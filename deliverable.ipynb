{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ae122a",
   "metadata": {},
   "source": [
    "- **Project Title:** *Explainable Recommendations with BigQuery AI: From Profiles to Insights*\n",
    "- **Problem Statement:** Most recommendation systems function as “black boxes,” surfacing items without offering context or transparency. This project uses BigQuery AI to automatically generate structured profiles of users and items, transform them into embeddings, and apply vector search to retrieve the most relevant matches. Each recommendation is then paired with an LLM-generated explanation, providing narrative reasoning that makes the system’s suggestions interpretable and trustworthy.\n",
    "- **Impact Statement:** This solution shows how organizations can build scalable, explainable recommendation engines directly within BigQuery without the need for specialized machine learning teams. By combining personalization with transparency, the approach improves user trust, helps businesses uncover actionable behavioral patterns, and extends seamlessly to domains such as e-commerce and media.\n",
    "- **Project Highlights**\n",
    "    - Developed adaptable, structured profiles for users and recipes using BigQuery AI, enabling easy customization for various business domains.\n",
    "    - Demonstrated that a straightforward recommendation system powered by BigQuery AI can slightly outperform the ALS baseline, simplifying implementation and highlighting the value of LLMs in recommendation workflows.\n",
    "    - Created an interactive UI for users to browse personalized recommendations alongside clear, LLM-generated explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622911ca",
   "metadata": {},
   "source": [
    "# User & Recipe Profiles with BigQuery AI: From Embeddings to \"Explainable\" Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356df23",
   "metadata": {},
   "source": [
    "\n",
    "Inspired by the DoorDash blog post on [Profile Generation with LLMs](https://careersatdoordash.com/blog/doordash-profile-generation-llms-understanding-consumers-merchants-and-items/), this notebook showcases how to build user and recipe profiles leveraging BigQuery AI. It also outlines a workflow for generating potential recommendations, each paired with an \"LLM-generated hypothesis\" to provide narrative context for the suggestions.\n",
    "\n",
    "This project addresses the challenges of **Approach 1 (The AI Architect)** and **Approach 2 (The Semantic Detective)** as described in the [Kaggle BigQuery Hackathon 2025](https://www.kaggle.com/competitions/bigquery-ai-hackathon/overview).\n",
    "\n",
    "This notebook is structured as follows:\n",
    "\n",
    "1. Data Sources\n",
    "    - Datasets used (including sources and descriptions)\n",
    "    - Preprocessing, splitting and uploading to BigQuery\n",
    "\n",
    "2. (Approach 1) Recipe Profiles Generation\n",
    "    - Profile schema design & prompt engineering\n",
    "    - Using BigQuery AI to generate recipe profiles\n",
    "\n",
    "3. (Approach 1) User Profiles Generation\n",
    "    - Profile schema design & prompt engineering\n",
    "    - Using BigQuery AI to generate user profiles\n",
    "\n",
    "4. (Approach 2) Vector Search vs ALS\n",
    "    - Using BigQuery AI to generate text embeddings\n",
    "    - Simple collaborative filtering\n",
    "    - Vector search for recommendations\n",
    "        - Naive approach\n",
    "        - HyDE (Hypothetical Document Embedding) approach\n",
    "    - Comparing results with ALS baseline\n",
    "\n",
    "5. (Approach 1) Explanation Generation\n",
    "    - Prompt engineering for explanation generation\n",
    "    - Using BigQuery AI to generate explanations for recommendations\n",
    "\n",
    "6. LLM-as-a-Judge as middle ground between Offline Metrics and A/B Testing\n",
    "\n",
    "7. (Approach 2) UI with Streamlit \n",
    "    - Hands-on interface to browse recommendations and their rationales\n",
    "        - Automatic Personalized Recommendations\n",
    "        - Semantic Search of Recipes\n",
    "\n",
    "8. Summary and Conclusions\n",
    "    - Feedback on BigQuery AI features\n",
    "    - User Survey on BigQuery AI features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595f34d",
   "metadata": {},
   "source": [
    "## Setup & Project Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86dc428f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os, json\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Optional\n",
    "import os, ast, numpy as np, pandas as pd\n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "import bigframes.pandas as bpd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=2)\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825cb3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=Medz5Ruj7eboye8tiUhy8kl1QTSbv5&access_type=offline&code_challenge=fWijhdCmAS4-EkH-LZhbJ8XvIpq7jtEb6AKc_Hk05cQ&code_challenge_method=S256\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "You are now logged in as [jeremy.matos@utec.edu.pe].\n",
      "Your current project is [kaggle-bigquery-471522].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n",
      "Updated property [core/project].\n",
      "\n",
      "Credentials saved to file: [/home/tenken/.config/gcloud/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"kaggle-bigquery-471522\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    }
   ],
   "source": [
    "os.environ['PROJECT_ID'] = input(\"Enter your Google Cloud Project ID: \")\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "\n",
    "subprocess.run(['gcloud', 'auth', 'login'])\n",
    "subprocess.run(['gcloud', 'config', 'set', 'project', PROJECT_ID])\n",
    "subprocess.run(['gcloud', 'auth', 'application-default', 'set-quota-project', PROJECT_ID])\n",
    "\n",
    "bpd.options.bigquery.project = PROJECT_ID\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "CONNECTION_ID = 'us.kaggle-connection'\n",
    "SCHEMA_NAME = 'deliverable'\n",
    "\n",
    "VALID_INTERACTIONS = f\"{PROJECT_ID}.{SCHEMA_NAME}.valid_interactions_windowed\"\n",
    "TRAIN_INTERACTIONS = f\"{PROJECT_ID}.{SCHEMA_NAME}.train_interactions_windowed\"\n",
    "SUBSET_RECIPE_IDS = f\"{PROJECT_ID}.{SCHEMA_NAME}.final_recipes\"\n",
    "SUBSET_USERS_IDS = f\"{PROJECT_ID}.{SCHEMA_NAME}.final_users\"\n",
    "\n",
    "RECIPES_ALL = f\"{PROJECT_ID}.{SCHEMA_NAME}.recipes\"\n",
    "OUT_DIM = 1024\n",
    "\n",
    "RECIPES_PARSED = f'{SCHEMA_NAME}.recipes_parsed'\n",
    "RECIPES_PROFILES_TABLE = f\"{SCHEMA_NAME}.recipe_profiles\"\n",
    "\n",
    "USERS_PARSED = f'{SCHEMA_NAME}.users_parsed'\n",
    "USERS_PROFILES_TABLE = f\"{SCHEMA_NAME}.user_profiles\"\n",
    "\n",
    "VECTOR_SEARCH_RESULTS_TABLE = f\"{SCHEMA_NAME}.vector_search_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88f30a",
   "metadata": {},
   "source": [
    "We use a [BigQuery client](https://cloud.google.com/bigquery/docs/datasets) to interact with the service in a more Pythonic way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd66e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a26e4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409 POST https://bigquery.googleapis.com/bigquery/v2/projects/kaggle-bigquery-471522/datasets?prettyPrint=false: Already Exists: Dataset kaggle-bigquery-471522:deliverable\n"
     ]
    }
   ],
   "source": [
    "dataset = bigquery.Dataset(f\"{client.project}.{SCHEMA_NAME}\")\n",
    "dataset.location = \"US\"\n",
    "\n",
    "try:\n",
    "    dataset = client.create_dataset(dataset, timeout=30)\n",
    "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb70b5",
   "metadata": {},
   "source": [
    "We create a Cloud Resource connection to interact with Vertex AI services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9763acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Already Exists: Connection\n",
      "projects/352240171839/locations/us/connections/kaggle-connection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['bq', 'mk', '--connection', '--location=us', '--connection_type=CLOUD_RESOURCE', 'kaggle-connection'], returncode=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['bq', 'mk', '--connection', '--location=us', '--connection_type=CLOUD_RESOURCE', f'{CONNECTION_ID.replace(\"us.\", \"\")}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b9457",
   "metadata": {},
   "source": [
    "Following the tutorials on [GitHub](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/bigquery_embeddings_vector_search.ipynb) we create a remote connection to the Text Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86acbae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x72f0d2945390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{SCHEMA_NAME}.text_embedding_model`\n",
    "REMOTE WITH \n",
    "    CONNECTION `{CONNECTION_ID}`\n",
    "    OPTIONS (ENDPOINT = 'gemini-embedding-001');\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28699f8",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179a96d",
   "metadata": {},
   "source": [
    "For the dataset selection, three considerations were made:\n",
    "- The datasets are publicly available (in line with the competition guidelines)\n",
    "- The dataset should align with the goal of addressing a real-world problem using solutions that integrate naturally with SQL workflows.\n",
    "- The dataset needs to include unstructured, messy, and mixed data\n",
    "\n",
    "\n",
    "We utilize the [FoodRecSysV1](https://www.kaggle.com/datasets/elisaxxygao/foodrecsysv1) dataset from Kaggle, which provides comprehensive user interactions with recipes; including ratings, comments, and rich recipe metadata. This dataset closely mirrors the real-world challenges encountered by platforms such as Cookpad, DoorDash, UberEats, and Rappi.\n",
    "\n",
    "Other datasets like [MealRec](https://arxiv.org/abs/2205.12133) and [MealRec++](https://github.com/WUT-IDEA/MealRecPlus) were also considered (and we can apply the same methodology of this notebook), but for the sake of simplicity and ease to start, we opted for FoodRecSysV1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105e2ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/tenken/.cache/kagglehub/datasets/elisaxxygao/foodrecsysv1/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"elisaxxygao/foodrecsysv1\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b8df08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw-data_interaction.csv',\n",
       " 'core-data-valid_rating.csv',\n",
       " 'core-data_recipe.csv',\n",
       " 'raw-data-images',\n",
       " 'core-data-test_rating.csv',\n",
       " 'core-data-train_rating.csv',\n",
       " 'core-data-images',\n",
       " 'raw-data_recipe.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6529d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "user_id                     object\n",
       "recipe_id                   object\n",
       "rating                     float64\n",
       "dateLastModified    datetime64[ns]\n",
       "month                        int32\n",
       "quarter                      int32\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>dateLastModified</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>676946.000</td>\n",
       "      <td>676946</td>\n",
       "      <td>676946.000</td>\n",
       "      <td>676946.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.469</td>\n",
       "      <td>2008-10-12 19:03:51.871918336</td>\n",
       "      <td>6.496</td>\n",
       "      <td>2.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2000-02-08 12:09:11.987000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>2007-07-20 09:30:30.988250112</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2009-05-15 03:51:38.998499840</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2010-08-31 19:02:24.820499968</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2011-10-14 17:43:08.433000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.574</td>\n",
       "      <td>1.148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating               dateLastModified      month    quarter\n",
       "count 676946.000                         676946 676946.000 676946.000\n",
       "mean       4.469  2008-10-12 19:03:51.871918336      6.496      2.502\n",
       "min        1.000     2000-02-08 12:09:11.987000      1.000      1.000\n",
       "25%        4.000  2007-07-20 09:30:30.988250112      3.000      1.000\n",
       "50%        5.000  2009-05-15 03:51:38.998499840      7.000      3.000\n",
       "75%        5.000  2010-08-31 19:02:24.820499968     10.000      4.000\n",
       "max        5.000     2011-10-14 17:43:08.433000     12.000      4.000\n",
       "std        0.860                            NaN      3.574      1.148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_train_rating.shape=(676946, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "user_id                     object\n",
       "recipe_id                   object\n",
       "rating                     float64\n",
       "dateLastModified    datetime64[ns]\n",
       "month                        int32\n",
       "quarter                      int32\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>dateLastModified</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>283440.000</td>\n",
       "      <td>283440</td>\n",
       "      <td>283440.000</td>\n",
       "      <td>283440.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.510</td>\n",
       "      <td>2015-02-09 01:26:51.432288512</td>\n",
       "      <td>6.310</td>\n",
       "      <td>2.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2013-01-31 22:55:07.660000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>2013-11-26 10:55:44.029000192</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2014-11-15 07:59:59.511500032</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2016-03-13 10:05:13.634749952</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2018-03-15 03:09:12.853000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.595</td>\n",
       "      <td>1.161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating               dateLastModified      month    quarter\n",
       "count 283440.000                         283440 283440.000 283440.000\n",
       "mean       4.510  2015-02-09 01:26:51.432288512      6.310      2.438\n",
       "min        1.000     2013-01-31 22:55:07.660000      1.000      1.000\n",
       "25%        4.000  2013-11-26 10:55:44.029000192      3.000      1.000\n",
       "50%        5.000  2014-11-15 07:59:59.511500032      6.000      2.000\n",
       "75%        5.000  2016-03-13 10:05:13.634749952     10.000      4.000\n",
       "max        5.000     2018-03-15 03:09:12.853000     12.000      4.000\n",
       "std        0.851                            NaN      3.595      1.161"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "user_id                     object\n",
       "recipe_id                   object\n",
       "rating                     float64\n",
       "dateLastModified    datetime64[ns]\n",
       "month                        int32\n",
       "quarter                      int32\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>dateLastModified</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>133459.000</td>\n",
       "      <td>133459</td>\n",
       "      <td>133459.000</td>\n",
       "      <td>133459.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.506</td>\n",
       "      <td>2012-05-23 09:30:25.575911936</td>\n",
       "      <td>6.870</td>\n",
       "      <td>2.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2011-10-14 17:46:56.443000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>2012-01-16 12:26:58.273499904</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2012-05-11 17:51:50.223000064</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2012-09-24 14:10:02.375000064</td>\n",
       "      <td>11.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000</td>\n",
       "      <td>2013-01-31 22:23:27.613000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.978</td>\n",
       "      <td>1.245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating               dateLastModified      month    quarter\n",
       "count 133459.000                         133459 133459.000 133459.000\n",
       "mean       4.506  2012-05-23 09:30:25.575911936      6.870      2.643\n",
       "min        1.000     2011-10-14 17:46:56.443000      1.000      1.000\n",
       "25%        4.000  2012-01-16 12:26:58.273499904      3.000      1.000\n",
       "50%        5.000  2012-05-11 17:51:50.223000064      7.000      3.000\n",
       "75%        5.000  2012-09-24 14:10:02.375000064     11.000      4.000\n",
       "max        5.000     2013-01-31 22:23:27.613000     12.000      4.000\n",
       "std        0.830                            NaN      3.978      1.245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_df(core: pd.DataFrame) -> pd.DataFrame:\n",
    "    core['user_id'] = core['user_id'].astype(str)\n",
    "    core['recipe_id'] = core['recipe_id'].astype(str)\n",
    "    core['dateLastModified'] = core['dateLastModified'].apply(lambda v: v.replace('\\n', ''))\n",
    "    core['dateLastModified'] = pd.to_datetime(core['dateLastModified'], format='ISO8601')\n",
    "    core['month'] = core['dateLastModified'].dt.month\n",
    "    core['quarter'] = core['dateLastModified'].dt.quarter\n",
    "    core['rating'] = core['rating'].astype(float)\n",
    "    \n",
    "    core = core.dropna(how='any').sort_values(by=['dateLastModified'], ascending=[True])\n",
    "    return core\n",
    "\n",
    "core_train_rating = pd.read_csv(f'{path}/core-data-train_rating.csv')\n",
    "core_train_rating = clean_df(core_train_rating)\n",
    "display('train', core_train_rating.dtypes, core_train_rating.describe())\n",
    "print(f\"{core_train_rating.shape=}\")\n",
    "\n",
    "\n",
    "core_test_rating = pd.read_csv(f'{path}/core-data-test_rating.csv')\n",
    "core_test_rating = clean_df(core_test_rating)\n",
    "display('test', core_test_rating.dtypes, core_test_rating.describe())\n",
    "\n",
    "\n",
    "core_val_rating = pd.read_csv(f'{path}/core-data-valid_rating.csv')\n",
    "core_val_rating = clean_df(core_val_rating)\n",
    "display('val', core_val_rating.dtypes, core_val_rating.describe())\n",
    "\n",
    "recipes = pd.read_csv('./data/food_recsys/raw-data_recipe.csv')\n",
    "recipes['recipe_id'] = recipes['recipe_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c72f4a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using last 24 weeks of training data to predict next 4 weeks of ratings, with at least 5 interactions in training and 5 interactions in validation for each user\n",
      "From 2011-04-29 17:43:08.433000 to 2011-11-11 17:46:56.443000\n"
     ]
    }
   ],
   "source": [
    "PREV_WEEKS = 24\n",
    "POST_WEEKS = 4\n",
    "MIN_INTERACTIONS_TRAIN = 5\n",
    "MIN_INTERACTIONS_VAL = 5\n",
    "print(f\"Using last {PREV_WEEKS} weeks of training data to predict next {POST_WEEKS} weeks of ratings, with at least {MIN_INTERACTIONS_TRAIN} interactions in training and {MIN_INTERACTIONS_VAL} interactions in validation for each user\")\n",
    "\n",
    "min_date_val = core_train_rating['dateLastModified'].max() - pd.Timedelta(weeks=PREV_WEEKS)\n",
    "max_date_val = core_val_rating['dateLastModified'].min() + pd.Timedelta(weeks=POST_WEEKS)\n",
    "\n",
    "print(f\"From {min_date_val} to {max_date_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d30af3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(common_users)=3729, len(common_recipes)=3764\n",
      "len(common_users)=2942, len(common_recipes)=2628\n",
      "Final datasets: 2730 train interactions, 1066 val interactions\n",
      "Min interactions per user in train: 5\n",
      "Min interactions per user in val: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'train_users'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1037986    176\n",
       "2043209    105\n",
       "2448319    104\n",
       "2702518     80\n",
       "2995814     70\n",
       "          ... \n",
       "2233245      5\n",
       "6392312      5\n",
       "3500863      5\n",
       "2524829      5\n",
       "4053273      5\n",
       "Name: count, Length: 131, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'val_users'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1037986    31\n",
       "2995814    29\n",
       "2043209    29\n",
       "2448319    24\n",
       "6067445    21\n",
       "           ..\n",
       "3047421     5\n",
       "484578      5\n",
       "5017867     5\n",
       "301943      5\n",
       "1054570     5\n",
       "Name: count, Length: 131, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 131, Recipes: 2048\n"
     ]
    }
   ],
   "source": [
    "# Use training data of last N weeks only\n",
    "core_train_rating = core_train_rating.loc[\n",
    "    lambda df: df['dateLastModified'] >= min_date_val\n",
    "]\n",
    "\n",
    "# Reduce val predictions to next POST_WEEKS only\n",
    "core_val_rating = core_val_rating.loc[\n",
    "    lambda df: (df['dateLastModified'] <= max_date_val) & (df['rating'] >= 3)\n",
    "]\n",
    "\n",
    "# Find common users and recipes first\n",
    "common_users = set(core_train_rating['user_id']).intersection(set(core_val_rating['user_id']))\n",
    "common_recipes = set(core_train_rating['recipe_id']).intersection(set(core_val_rating['recipe_id']))\n",
    "print(f\"{len(common_users)=}, {len(common_recipes)=}\")\n",
    "\n",
    "# Filter both datasets to only include common users and recipes\n",
    "train_users = core_train_rating[\n",
    "    core_train_rating['user_id'].isin(common_users) & \n",
    "    core_train_rating['recipe_id'].isin(common_recipes)\n",
    "]\n",
    "val_users = core_val_rating[\n",
    "    core_val_rating['user_id'].isin(common_users) & \n",
    "    core_val_rating['recipe_id'].isin(common_recipes)\n",
    "]\n",
    "\n",
    "common_users = set(train_users['user_id']).intersection(set(val_users['user_id']))\n",
    "common_recipes = set(train_users['recipe_id']).intersection(set(val_users['recipe_id']))\n",
    "print(f\"{len(common_users)=}, {len(common_recipes)=}\")\n",
    "\n",
    "# Now filter by minimum interactions AFTER filtering by common users/recipes\n",
    "train_user_counts = train_users['user_id'].value_counts()\n",
    "val_user_counts = val_users['user_id'].value_counts()\n",
    "train_recipe_counts = train_users['recipe_id'].value_counts()\n",
    "val_recipe_counts = val_users['recipe_id'].value_counts()\n",
    "\n",
    "# Users and recipes with at least MIN_INTERACTIONS interactions in FINAL filtered datasets\n",
    "users_min_it_train = set(train_user_counts[train_user_counts >= MIN_INTERACTIONS_TRAIN].index)\n",
    "users_min_it_val = set(val_user_counts[val_user_counts >= MIN_INTERACTIONS_VAL].index)\n",
    "\n",
    "# Final common users and recipes with minimum interactions\n",
    "final_users = users_min_it_train.intersection(users_min_it_val)\n",
    "\n",
    "# Apply final filter\n",
    "train_users = train_users[train_users['user_id'].isin(final_users)]\n",
    "val_users = val_users[(val_users['user_id'].isin(final_users))]\n",
    "final_recipes = set(train_users['recipe_id'].values).union(set(val_users['recipe_id'].values))\n",
    "\n",
    "# Use final recipes for all recipe datasets\n",
    "train_recipes = val_recipes = recipes[recipes['recipe_id'].isin(final_recipes)]\n",
    "\n",
    "\n",
    "print(f\"Final datasets: {len(train_users)} train interactions, {len(val_users)} val interactions\")\n",
    "\n",
    "# Verify minimum interactions constraint\n",
    "print(f\"Min interactions per user in train: {train_users['user_id'].value_counts().min()}\")\n",
    "print(f\"Min interactions per user in val: {val_users['user_id'].value_counts().min()}\")\n",
    "\n",
    "display('train_users', train_users['user_id'].value_counts().sort_values(ascending=False))\n",
    "display('val_users', val_users['user_id'].value_counts().sort_values(ascending=False))\n",
    "print(f\"Users: {len(final_users)}, Recipes: {len(final_recipes)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dd96f",
   "metadata": {},
   "source": [
    "We'll finally use a total of 131 users and 2048 recipes, a size that balances data volume and execution time for demonstration purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb05c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5601/349922751.py:3: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  train_users.to_gbq(TRAIN_INTERACTIONS, if_exists='replace')\n",
      "100%|██████████| 1/1 [00:00<00:00, 12122.27it/s]\n",
      "/tmp/ipykernel_5601/349922751.py:4: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  val_users.to_gbq(VALID_INTERACTIONS, if_exists='replace')\n",
      "100%|██████████| 1/1 [00:00<00:00, 10230.01it/s]\n",
      "/tmp/ipykernel_5601/349922751.py:5: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  train_recipes[['recipe_id']].to_gbq(SUBSET_RECIPE_IDS, if_exists='replace')\n",
      "100%|██████████| 1/1 [00:00<00:00, 9709.04it/s]\n",
      "/tmp/ipykernel_5601/349922751.py:6: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  pd.DataFrame({'user_id': list(final_users)}).to_gbq(SUBSET_USERS_IDS, if_exists='replace')\n",
      "100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Upload tables to BigQuery\n",
    "\n",
    "train_users.to_gbq(TRAIN_INTERACTIONS, if_exists='replace')\n",
    "val_users.to_gbq(VALID_INTERACTIONS, if_exists='replace')\n",
    "train_recipes[['recipe_id']].to_gbq(SUBSET_RECIPE_IDS, if_exists='replace')\n",
    "pd.DataFrame({'user_id': list(final_users)}).to_gbq(SUBSET_USERS_IDS, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1bf359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5601/1013056983.py:1: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  recipes.to_gbq(RECIPES_ALL, if_exists='replace')\n",
      "100%|██████████| 1/1 [00:00<00:00, 7219.11it/s]\n"
     ]
    }
   ],
   "source": [
    "recipes.to_gbq(RECIPES_ALL, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c4f8c",
   "metadata": {},
   "source": [
    "Next, we're going to generate profiles in line with the [Spotify blog](https://research.atspotify.com/2025/9/profile-aware-llm-as-a-judge-for-podcasts-a-better-middle-ground-between). But first, let's define some utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19c94fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema_to_prompt_with_descriptions(model_class) -> str:\n",
    "    prompt = \"\"\n",
    "    for k, v in model_class.model_json_schema()['properties'].items():\n",
    "        desc = v.get('description', '')\n",
    "        prompt += f\" {k} ({desc}) \"\n",
    "    return f\"[ {prompt} ]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad24b5bb",
   "metadata": {},
   "source": [
    "# Recipe Profiles Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf54445",
   "metadata": {},
   "source": [
    "We start cleaning and parsing some columns to make them suitable and more understandable for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abb42144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_ingredients(text: str) -> str:\n",
    "    if pd.isna(text): return \"\"\n",
    "    return \"\\n\".join([f\"- {v}\" for v in str(text).split('^')])\n",
    "\n",
    "\n",
    "def prep_directions(text: str) -> str:\n",
    "    if pd.isna(text): return \"\"\n",
    "    s = str(text)\n",
    "    # Some rows look like dict-strings with 'directions' inside; just fall back to raw text\n",
    "    # Optionally, try to parse if it starts with \"{\"\n",
    "    if s.strip().startswith(\"{\"):\n",
    "        try:\n",
    "            d = ast.literal_eval(s)\n",
    "            # common keys: 'directions' (string) or list\n",
    "            v = d.get('directions', \"\")\n",
    "            v = str(v).split('\\n')\n",
    "            v = [x.strip() for x in v if len(x.strip()) > 0]\n",
    "            v = [f\". {x}\" if x and x[0].isupper() else x for x in v]\n",
    "\n",
    "            return \" \".join(v).strip(\".\").replace(\" . \", \". \").replace(\"..\", \".\").strip()\n",
    "        except Exception:\n",
    "            return s.lower()\n",
    "    return s.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5c1bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes = bpd.read_gbq(f\"\"\"\n",
    "SELECT * FROM `{SUBSET_RECIPE_IDS}`\n",
    "LEFT JOIN `{RECIPES_ALL}` USING(recipe_id)\n",
    "\"\"\")\n",
    "\n",
    "# Convert to pandas DataFrame to use custom functions, then back to BigFrames\n",
    "df_recipes_pandas = df_recipes.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70803c3f",
   "metadata": {},
   "source": [
    "We create `parsed_ingredients` and `parsed_recipe` columns to then insert it into the prompt for profile generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c194da04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:01<00:00, 1874.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Load job 04b89c5e-1ccf-412b-8193-3bc1506a6b51 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=kaggle-bigquery-471522&j=bq:US:04b89c5e-1ccf-412b-8193-3bc1506a6b51&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Query job 5e308e63-e6b9-49c0-9a93-3499acbd422b is DONE. 1.1 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=kaggle-bigquery-471522&j=bq:US:5e308e63-e6b9-49c0-9a93-3499acbd422b&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'kaggle-bigquery-471522.deliverable.recipes_parsed'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrition_values = []\n",
    "for idx, row in tqdm(df_recipes_pandas.iterrows(), total=len(df_recipes_pandas)):\n",
    "    nutritions_dict = ast.literal_eval(row['nutritions'])\n",
    "    \n",
    "    row_info = {'recipe_id': row['recipe_id']}\n",
    "    nutritions_info = {}\n",
    "    for k in ['niacin', 'sugars', 'sodium', 'carbohydrates', 'vitaminB6', 'calories', 'thiamin', 'fat', 'folate', 'caloriesFromFat', 'calcium', 'fiber', 'magnesium', 'iron', 'cholesterol', 'protein', 'vitaminA', 'potassium', 'saturatedFat', 'vitaminC']:\n",
    "        if k in nutritions_dict:\n",
    "            nutritions_info[k] = nutritions_dict[k].get('percentDailyValue', -1)\n",
    "            if nutritions_info[k] is not None:\n",
    "                v = str(nutritions_info[k]).strip()\n",
    "                if v == '< 1':\n",
    "                    nutritions_info[k] = 0.0\n",
    "                # if v == '-':\n",
    "                #     nutritions_info[k] = -1\n",
    "                \n",
    "                try:\n",
    "                    nutritions_info[k] = f\"{nutritions_info[k]} percent\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "    \n",
    "    row_info['percent_daily_values'] = \"\\n\".join([f\"{k}: {v}\" for k, v in nutritions_info.items()])\n",
    "    nutrition_values.append(row_info)\n",
    "\n",
    "nutrition_df = pd.DataFrame(nutrition_values).fillna(-2)\n",
    "\n",
    "df_recipes_pandas['parsed_ingredients'] = df_recipes_pandas['ingredients'].apply(prep_ingredients)\n",
    "df_recipes_pandas['parsed_recipe'] = df_recipes_pandas['cooking_directions'].apply(prep_directions)\n",
    "df_recipes_pandas = df_recipes_pandas.merge(nutrition_df, how='left', on='recipe_id')\n",
    "df_recipes_pandas['title'] = df_recipes_pandas['recipe_name']\n",
    "df_recipes = bpd.DataFrame(df_recipes_pandas)\n",
    "\n",
    "# Upload the new table in BigQuery\n",
    "df_recipes.to_gbq(\n",
    "    destination_table=f\"{PROJECT_ID}.{RECIPES_PARSED}\",\n",
    "    if_exists='replace',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e35ffb",
   "metadata": {},
   "source": [
    "Following the [DoorDash blog](https://careersatdoordash.com/blog/doordash-profile-generation-llms-understanding-consumers-merchants-and-items/) we define the structure and attributes of the \"Recipe Profile\" (item profiles). In this case we use a Pydantic model to define the schema, which then parsed as part of the prompt using the function `schema_to_prompt_with_descriptions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b85692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeProfile(BaseModel):\n",
    "    food_type: str = Field(description=\"Type of food, e.g., dessert, main course, appetizer\")\n",
    "    cuisine_type: str = Field(description=\"Cuisine type, e.g., Italian, Chinese, Mexican, American\")\n",
    "    dietary_preferences: List[str] = Field(description=\"Dietary preferences, e.g., omnivore, vegetarian, vegan, gluten-free\")\n",
    "    flavor_profile: List[str] = Field(description=\"Flavor profile, e.g., spicy, sweet, savory\")\n",
    "    serving_daypart: List[str] = Field(description=\"Suitable dayparts, e.g., breakfast, lunch, dinner\")\n",
    "    notes: str = Field(description=\"Short rationale summarizing the recipe profile\")\n",
    "    target_audience: str = Field(description=\"Types of users who would likely enjoy this recipe based on cooking skill level, flavor intensity, dietary needs, and lifestyle preferences. Helps recommendation systems match recipes to appropriate user profiles.\")\n",
    "    justification: str = Field(description=\"Detailed explanation of how the profile was determined Describe why the food type, cuisine type, dietary preferences, flavor profile, and serving daypart were chosen based on the ingredients and cooking directions. Is not allowed to use quotes or complex punctuation in this field.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04fa17e",
   "metadata": {},
   "source": [
    "This schema could be enhanced by using more restrictive field types, such as `Enums` or `Literal` for categorical attributes. This would make it easier to apply business logic based on the extracted category metadata generated by the LLM in future iterations. \n",
    "\n",
    "Then, we define the prompt template to generate the recipe profiles, as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "744fd3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the title, ingredients, cooking directions and percent daily values provided, create a recipe profile that summarizes the key characteristics of this recipe. Your response must follow this exact structure: [  food_type (Type of food, e.g., dessert, main course, appetizer)  cuisine_type (Cuisine type, e.g., Italian, Chinese, Mexican, American)  dietary_preferences (Dietary preferences, e.g., omnivore, vegetarian, vegan, gluten-free)  flavor_profile (Flavor profile, e.g., spicy, sweet, savory)  serving_daypart (Suitable dayparts, e.g., breakfast, lunch, dinner)  notes (Short rationale summarizing the recipe profile)  target_audience (Types of users who would likely enjoy this recipe based on cooking skill level, flavor intensity, dietary needs, and lifestyle preferences. Helps recommendation systems match recipes to appropriate user profiles.)  justification (Detailed explanation of how the profile was determined Describe why the food type, cuisine type, dietary preferences, flavor profile, and serving daypart were chosen based on the ingredients and cooking directions. Is not allowed to use quotes or complex punctuation in this field.)  ]. IMPORTANT: Do not use quotation marks or complex punctuation in your response. Use simple words and avoid any quotes, apostrophes, or special characters.\n"
     ]
    }
   ],
   "source": [
    "recipe_profile_prompt = f\"\"\"Based on the title, ingredients, cooking directions and percent daily values provided, create a recipe profile that summarizes the key characteristics of this recipe. Your response must follow this exact structure: {schema_to_prompt_with_descriptions(RecipeProfile)}. IMPORTANT: Do not use quotation marks or complex punctuation in your response. Use simple words and avoid any quotes, apostrophes, or special characters.\"\"\"\n",
    "\n",
    "print(recipe_profile_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736780c7",
   "metadata": {},
   "source": [
    "We set the `temperature` parameter to **1.0** to promote creativity and encourage the model to explore a wide range of recipe characteristics during profile generation. The `maxOutputTokens` is set to `2048` to stay within the [Gemini Embedding Model's input token limit](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings). Additionally, we allocate up to `1024` thinking tokens to leverage the model’s reasoning abilities, aiming for a balance between accuracy and latency. Finally, we choose `gemini-2.5-flash` model for speed and cost efficiency.\n",
    "\n",
    "<!-- https://developers.googleblog.com/en/gemini-embedding-available-gemini-api/ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb9f7763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WITH ai_responses AS (\n",
      "  SELECT \n",
      "    s.recipe_id, \n",
      "    s.title, \n",
      "    s.ingredients, \n",
      "    s.cooking_directions, \n",
      "    s.nutritions, \n",
      "    s.reviews, \n",
      "    s.parsed_ingredients, \n",
      "    s.parsed_recipe,\n",
      "    AI.GENERATE(('Based on the title, ingredients, cooking directions and percent daily values provided, create a recipe profile that summarizes the key characteristics of this recipe. Your response must follow this exact structure: [  food_type (Type of food, e.g., dessert, main course, appetizer)  cuisine_type (Cuisine type, e.g., Italian, Chinese, Mexican, American)  dietary_preferences (Dietary preferences, e.g., omnivore, vegetarian, vegan, gluten-free)  flavor_profile (Flavor profile, e.g., spicy, sweet, savory)  serving_daypart (Suitable dayparts, e.g., breakfast, lunch, dinner)  notes (Short rationale summarizing the recipe profile)  target_audience (Types of users who would likely enjoy this recipe based on cooking skill level, flavor intensity, dietary needs, and lifestyle preferences. Helps recommendation systems match recipes to appropriate user profiles.)  justification (Detailed explanation of how the profile was determined Describe why the food type, cuisine type, dietary preferences, flavor profile, and serving daypart were chosen based on the ingredients and cooking directions. Is not allowed to use quotes or complex punctuation in this field.)  ]. IMPORTANT: Do not use quotation marks or complex punctuation in your response. Use simple words and avoid any quotes, apostrophes, or special characters.', s.parsed_ingredients, s.parsed_recipe, s.percent_daily_values),\n",
      "        connection_id => 'us.kaggle-connection',\n",
      "        endpoint => 'gemini-2.5-flash',\n",
      "        model_params => JSON '{\"generationConfig\":{\"temperature\": 1.0, \"maxOutputTokens\": 2048, \"thinking_config\": {\"thinking_budget\": 1024} } }',\n",
      "        output_schema => 'food_type STRING, cuisine_type STRING, dietary_preferences ARRAY<STRING>, flavor_profile ARRAY<STRING>, serving_daypart ARRAY<STRING>, notes STRING, target_audience STRING, justification STRING'\n",
      "    ) AS ai_result\n",
      "  FROM (SELECT * FROM `deliverable.recipes_parsed`) s\n",
      ")\n",
      "SELECT \n",
      "  *,\n",
      "  ai_result.full_response AS recipe_profile,\n",
      "  JSON_EXTRACT_SCALAR(ai_result.full_response, '$.candidates[0].content.parts[0].text') AS recipe_profile_text\n",
      "FROM ai_responses\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recipe_profile_generation_query = f\"\"\"\n",
    "WITH ai_responses AS (\n",
    "  SELECT \n",
    "    s.recipe_id, \n",
    "    s.title, \n",
    "    s.ingredients, \n",
    "    s.cooking_directions, \n",
    "    s.nutritions, \n",
    "    s.reviews, \n",
    "    s.parsed_ingredients, \n",
    "    s.parsed_recipe,\n",
    "    AI.GENERATE(('{recipe_profile_prompt}', s.parsed_ingredients, s.parsed_recipe, s.percent_daily_values),\n",
    "        connection_id => '{CONNECTION_ID}',\n",
    "        endpoint => 'gemini-2.5-flash',\n",
    "        model_params => JSON '{{\"generationConfig\":{{\"temperature\": 1.0, \"maxOutputTokens\": 2048, \"thinking_config\": {{\"thinking_budget\": 1024}} }} }}',\n",
    "        output_schema => 'food_type STRING, cuisine_type STRING, dietary_preferences ARRAY<STRING>, flavor_profile ARRAY<STRING>, serving_daypart ARRAY<STRING>, notes STRING, target_audience STRING, justification STRING'\n",
    "    ) AS ai_result\n",
    "  FROM (SELECT * FROM `{RECIPES_PARSED}`) s\n",
    ")\n",
    "SELECT \n",
    "  *,\n",
    "  ai_result.full_response AS recipe_profile,\n",
    "  JSON_EXTRACT_SCALAR(ai_result.full_response, '$.candidates[0].content.parts[0].text') AS recipe_profile_text\n",
    "FROM ai_responses\n",
    "\"\"\"\n",
    "\n",
    "print(recipe_profile_generation_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf85209",
   "metadata": {},
   "source": [
    "With this prompt, we can execute the SQL query using the BigQuery client. We encountered some challenges when specifying the prompt directly within the SQL query, such as issues with quotation marks (to highlight words), punctuation and line breaks, which are common in longer prompts. To mitigate these problems, we define the prompt as a single paragraph. It would be helpful if there were a way to use multi-line strings directly in SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8586b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"avg_logprobs\": -0.9889099980743838,\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"{\\n  \\\"cuisine_type\\\": \\\"Mexican\\\",\\n  \\\"dietary_preferences\\\": [\\n    \\\"vegetarian\\\"\\n  ],\\n  \\\"flavor_profile\\\": [\\n    \\\"sweet\\\",\\n    \\\"savory\\\",\\n    \\\"tangy\\\"\\n  ],\\n  \\\"food_type\\\": \\\"main course\\\",\\n  \\\"justification\\\": \\\"The food type is main course because the recipe involves substantial ingredients like sweet potatoes black beans and cheese enclosed in tortillas cooked and served in wedges making it a filling meal. The cuisine type is Mexican due to the prominent use of tortillas black beans and salsa which are staples in Mexican and Tex-Mex cooking along with the quesadilla preparation method. Dietary preferences are vegetarian because the ingredients include sweet potatoes black beans and tortillas which are plant-based along with cheddar cheese which is dairy but no meat or poultry is present. The flavor profile is sweet from the sweet potatoes savory from the black beans tortillas and cheese and tangy from the cheddar cheese and optional salsa. Serving daypart includes lunch dinner and snack as quesadillas are versatile and can be enjoyed for a quick meal or a substantial snack at various times of the day.\\\",\\n  \\\"notes\\\": \\\"A satisfying vegetarian Mexican inspired quesadilla combining sweet potatoes black beans and cheddar cheese offering a balanced sweet and savory flavor profile ideal for various meal times.\\\",\\n  \\\"serving_daypart\\\": [\\n    \\\"lunch\\\",\\n    \\\"dinner\\\",\\n    \\\"snack\\\"\\n  ],\\n  \\\"target_audience\\\": \\\"Vegetarians and omnivores looking for a comforting flavorful and easy-to-prepare meal or substantial snack This recipe is well-suited for beginner to intermediate cooks and families who enjoy a blend of sweet and savory tastes with a mild flavor intensity\\\"\\n}\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finish_reason\": \"STOP\",\n",
      "      \"score\": -351.06304931640625\n",
      "    }\n",
      "  ],\n",
      "  \"create_time\": \"2025-09-21T01:57:38.346709Z\",\n",
      "  \"model_version\": \"gemini-2.5-flash\",\n",
      "  \"response_id\": \"klvPaNWUFdujhMIPvYWI2A4\",\n",
      "  \"usage_metadata\": {\n",
      "    \"billable_prompt_usage\": {\n",
      "      \"text_count\": 2407\n",
      "    },\n",
      "    \"candidates_token_count\": 355,\n",
      "    \"candidates_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 355\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_token_count\": 699,\n",
      "    \"prompt_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 699\n",
      "      }\n",
      "    ],\n",
      "    \"thoughts_token_count\": 821,\n",
      "    \"total_token_count\": 1875,\n",
      "    \"traffic_type\": \"ON_DEMAND\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"cuisine_type\": \"Mexican\",\n",
      "  \"dietary_preferences\": [\n",
      "    \"vegetarian\"\n",
      "  ],\n",
      "  \"flavor_profile\": [\n",
      "    \"sweet\",\n",
      "    \"savory\",\n",
      "    \"tangy\"\n",
      "  ],\n",
      "  \"food_type\": \"main course\",\n",
      "  \"justification\": \"The food type is main course because the recipe involves substantial ingredients like sweet potatoes black beans and cheese enclosed in tortillas cooked and served in wedges making it a filling meal. The cuisine type is Mexican due to the prominent use of tortillas black beans and salsa which are staples in Mexican and Tex-Mex cooking along with the quesadilla preparation method. Dietary preferences are vegetarian because the ingredients include sweet potatoes black beans and tortillas which are plant-based along with cheddar cheese which is dairy but no meat or poultry is present. The flavor profile is sweet from the sweet potatoes savory from the black beans tortillas and cheese and tangy from the cheddar cheese and optional salsa. Serving daypart includes lunch dinner and snack as quesadillas are versatile and can be enjoyed for a quick meal or a substantial snack at various times of the day.\",\n",
      "  \"notes\": \"A satisfying vegetarian Mexican inspired quesadilla combining sweet potatoes black beans and cheddar cheese offering a balanced sweet and savory flavor profile ideal for various meal times.\",\n",
      "  \"serving_daypart\": [\n",
      "    \"lunch\",\n",
      "    \"dinner\",\n",
      "    \"snack\"\n",
      "  ],\n",
      "  \"target_audience\": \"Vegetarians and omnivores looking for a comforting flavorful and easy-to-prepare meal or substantial snack This recipe is well-suited for beginner to intermediate cooks and families who enjoy a blend of sweet and savory tastes with a mild flavor intensity\"\n",
      "}\n",
      "r_profile={'cuisine_type': 'Mexican', 'dietary_preferences': ['vegetarian'], 'flavor_profile': ['sweet', 'savory', 'tangy'], 'food_type': 'main course', 'justification': 'The food type is main course because the recipe involves substantial ingredients like sweet potatoes black beans and cheese enclosed in tortillas cooked and served in wedges making it a filling meal. The cuisine type is Mexican due to the prominent use of tortillas black beans and salsa which are staples in Mexican and Tex-Mex cooking along with the quesadilla preparation method. Dietary preferences are vegetarian because the ingredients include sweet potatoes black beans and tortillas which are plant-based along with cheddar cheese which is dairy but no meat or poultry is present. The flavor profile is sweet from the sweet potatoes savory from the black beans tortillas and cheese and tangy from the cheddar cheese and optional salsa. Serving daypart includes lunch dinner and snack as quesadillas are versatile and can be enjoyed for a quick meal or a substantial snack at various times of the day.', 'notes': 'A satisfying vegetarian Mexican inspired quesadilla combining sweet potatoes black beans and cheddar cheese offering a balanced sweet and savory flavor profile ideal for various meal times.', 'serving_daypart': ['lunch', 'dinner', 'snack'], 'target_audience': 'Vegetarians and omnivores looking for a comforting flavorful and easy-to-prepare meal or substantial snack This recipe is well-suited for beginner to intermediate cooks and families who enjoy a blend of sweet and savory tastes with a mild flavor intensity'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5601/584357236.py:11: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  df_recipes_profiles.to_gbq(\n",
      "100%|██████████| 1/1 [00:00<00:00, 8192.00it/s]\n"
     ]
    }
   ],
   "source": [
    "recipe_rows = client.query_and_wait(recipe_profile_generation_query)\n",
    "df_recipes_profiles = recipe_rows.to_dataframe()\n",
    "\n",
    "response = json.loads(df_recipes_profiles['recipe_profile'].iloc[0])\n",
    "r_profile = json.loads(response['candidates'][0]['content']['parts'][0]['text'])\n",
    "                      \n",
    "print(json.dumps(response, indent=2))\n",
    "print(json.dumps(json.loads(df_recipes_profiles['recipe_profile_text'].iloc[0]), indent=2))\n",
    "print(f\"{r_profile=}\")\n",
    "\n",
    "df_recipes_profiles.to_gbq(\n",
    "    destination_table=f\"{PROJECT_ID}.{RECIPES_PROFILES_TABLE}\",\n",
    "    if_exists='replace',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095acf73",
   "metadata": {},
   "source": [
    "# User Profiles Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a978888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [01:13<00:00, 27.90it/s] \n"
     ]
    }
   ],
   "source": [
    "df_recipe_metadata = client.query_and_wait(f\"\"\"SELECT recipe_id, title, parsed_ingredients, parsed_recipe, recipe_profile_text, reviews FROM `{RECIPES_PROFILES_TABLE}`\"\"\").to_dataframe()\n",
    "\n",
    "reviews = []\n",
    "for idx, row in tqdm(df_recipe_metadata.iterrows(), total=len(df_recipe_metadata)):\n",
    "    recipe_id = row['recipe_id']\n",
    "    interactions_dict = ast.literal_eval(row['reviews'])\n",
    "    for k, v in interactions_dict.items():\n",
    "        reviews.append({\n",
    "            'recipe_id': recipe_id,\n",
    "            'user_id': str(k),\n",
    "            **v\n",
    "        })\n",
    "reviews_df = pd.DataFrame(reviews)\n",
    "reviews_df.columns = reviews_df.columns.str.lower()\n",
    "reviews_df['datelastmodified'] = pd.to_datetime(reviews_df['datelastmodified'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9055c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_COLS = 'user_id, recipe_id, rating, datelastmodified'\n",
    "df_train_users = client.query_and_wait(f\"\"\"SELECT {SUBSET_COLS} FROM `{TRAIN_INTERACTIONS}`\"\"\").to_dataframe()\n",
    "df_valid_users = client.query_and_wait(f\"\"\"SELECT {SUBSET_COLS} FROM `{VALID_INTERACTIONS}`\"\"\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46ada9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final users: 131\n",
      "        rating            datelastmodified\n",
      "count 2730.000                        2730\n",
      "mean     4.496  2011-07-27 01:47:37.662131\n",
      "min      1.000  2011-04-29 18:43:20.453000\n",
      "25%      4.000  2011-06-14 12:31:13.382750\n",
      "50%      5.000  2011-07-29 09:15:59.395000\n",
      "75%      5.000  2011-09-07 19:15:58.460500\n",
      "max      5.000  2011-10-14 17:24:08.330000\n",
      "std      0.757                         NaN\n",
      "        rating            datelastmodified\n",
      "count 1066.000                        1066\n",
      "mean     4.559  2011-10-29 01:36:00.828909\n",
      "min      3.000  2011-10-14 20:03:19.147000\n",
      "25%      4.000  2011-10-22 12:28:31.182000\n",
      "50%      5.000  2011-10-28 18:52:05.890000\n",
      "75%      5.000  2011-11-05 06:16:04.777250\n",
      "max      5.000  2011-11-11 17:43:12.483000\n",
      "std      0.629                         NaN\n"
     ]
    }
   ],
   "source": [
    "# Drop users in valid not present in train_set\n",
    "FINAL_USERS = set(df_train_users['user_id'].unique()).intersection(set(df_valid_users['user_id'].unique()))\n",
    "print(f\"Final users: {len(FINAL_USERS)}\")\n",
    "\n",
    "df_users_history = df_train_users[df_train_users['user_id'].isin(FINAL_USERS)].reset_index(drop=True)\n",
    "df_users_history['datelastmodified'] = pd.to_datetime(df_users_history['datelastmodified'])\n",
    "df_users_history = df_users_history.merge(\n",
    "    reviews_df[['user_id', 'recipe_id', 'datelastmodified', 'text']], how='left', \n",
    "    on=['user_id', 'recipe_id', 'datelastmodified'],\n",
    "    validate='one_to_one'\n",
    ").rename(columns={'text': 'user_comment'})\n",
    "\n",
    "df_valid_users = df_valid_users[df_valid_users['user_id'].isin(FINAL_USERS)].reset_index(drop=True)\n",
    "\n",
    "print(df_users_history.describe())\n",
    "print(df_valid_users.describe())\n",
    "\n",
    "df_users_to_profile = df_valid_users.groupby('user_id').agg({'recipe_id': 'unique'}).reset_index().rename(columns={\n",
    "    'recipe_id': 'rec_gt'\n",
    "})  # , 'datelastmodified'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ec940",
   "metadata": {},
   "source": [
    "For the user profile generation, we take advantage of the context window size of the Gemini models to provide a list of their historical interactions (ratings and comments) as part of the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_history(user_id: int, n: int = 25, k_min: int = 5) -> list:\n",
    "    \"\"\"Get the top-n most recent recipes the user has interacted with.\"\"\"\n",
    "    user_history = df_users_history[df_users_history['user_id'] == user_id]\n",
    "    user_history = user_history.sort_values(by='datelastmodified', ascending=False).head(n)\n",
    "    assert len(user_history) >= k_min, f\"User {user_id} has less than {k_min} interactions in the training set.\"\n",
    "\n",
    "    user_history['date'] = user_history['datelastmodified'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    return user_history[['recipe_id', 'rating', 'date', 'user_comment']].to_dict('records')\n",
    "\n",
    "\n",
    "def format_user_history(user_history: list[dict]) -> str:\n",
    "    \"\"\"Format the user history as a bulleted list.\"\"\"\n",
    "\n",
    "    user_info = \"\"\n",
    "    avg_rating = 0\n",
    "    for entry in user_history:\n",
    "        recipe_metadata = df_recipe_metadata.loc[lambda df: df['recipe_id'] == entry['recipe_id'], ['recipe_id', 'title', 'parsed_ingredients', 'parsed_recipe', 'recipe_profile_text']].reset_index(drop=True).iloc[0]\n",
    "        avg_rating += entry['rating']\n",
    "\n",
    "        user_info += (\n",
    "            f\"\\n>>> Recipe Title: {recipe_metadata['title']}\\n\"\n",
    "            f\">>> User Rating: {entry['rating']}\\n\"\n",
    "            f\">>> Date of Interaction: {entry['date']}\\n\\n\"\n",
    "            f\">>> User Comment: {entry['user_comment']}\\n\\n\"\n",
    "            # TODO: Those columns are missing\n",
    "            # f\"Recipe Average Rating: {row['aver_rate']}\\n\"\n",
    "            f\">>> Ingredients:\\n{recipe_metadata['parsed_ingredients']}\\n\\n\"\n",
    "            f\">>> Cooking Directions:\\n{recipe_metadata['parsed_recipe']}\\n\"\n",
    "        )\n",
    "        user_info += \"--------------------------------------------\\n\"\n",
    "    avg_rating /= len(user_history)\n",
    "    user_info = f\"The user has rated {len(user_history)} recipes, with an average rating of {avg_rating:.2f}.\\n{user_info}\"\n",
    "    user_info = \"########################################### USER HISTORY START ###########################################\\n\" + user_info\n",
    "    user_info += \"########################################### USER HISTORY END ###########################################\\n\"\n",
    "    \n",
    "    return user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "609a89d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Load job 1c805cc1-12c5-4154-ab47-92618c79b7c4 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=kaggle-bigquery-471522&j=bq:US:1c805cc1-12c5-4154-ab47-92618c79b7c4&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Query job eefa4c7f-6a58-4f5e-8e00-a6a93c551e3b is DONE. 3.3 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=kaggle-bigquery-471522&j=bq:US:eefa4c7f-6a58-4f5e-8e00-a6a93c551e3b&page=queryresults\">Open Job</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'kaggle-bigquery-471522.deliverable.users_parsed'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_users_to_profile['user_history'] = df_users_to_profile['user_id'].apply(get_user_history)\n",
    "df_users_to_profile['n_history'] = df_users_to_profile['user_history'].apply(len)\n",
    "\n",
    "df_users_to_profile['n_history'].plot.hist(bins=30)\n",
    "\n",
    "# print(format_user_history(df_users_to_profile['user_history'].iloc[0]))\n",
    "df_users_to_profile['history_string'] = df_users_to_profile['user_history'].apply(format_user_history)\n",
    "\n",
    "bpd.DataFrame(df_users_to_profile).to_gbq(\n",
    "    destination_table=f\"{PROJECT_ID}.{USERS_PARSED}\",\n",
    "    if_exists='replace',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f51563b",
   "metadata": {},
   "source": [
    "As in the recipe profiles, we define a Pydantic model, that it can be improved and adapted to the specific business case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c64122a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserProfile(BaseModel):\n",
    "    liked_cuisines: List[str] = Field(description=\"List of cuisines the user enjoys most, ranked by preference based on their interaction history and ratings\")\n",
    "    cuisine_preference: str = Field(description=\"Primary cuisine type the user gravitates towards (e.g., Mediterranean, Asian Fusion, Traditional American)\")\n",
    "    dietary_preference: str = Field(description=\"Main dietary restriction or lifestyle the user follows (e.g., Vegetarian, Low-carb, No restrictions)\")\n",
    "\n",
    "    food_preferences: List[str] = Field(description=\"Preferred food categories and meal types (e.g., comfort food, healthy salads, baked goods, grilled meats)\")\n",
    "    top_cuisine_choices: List[str] = Field(description=\"Specific regional or ethnic cuisines the user frequently rates highly (e.g., Thai, Southern BBQ, French pastry)\")\n",
    "    dietary_preferences: List[str] = Field(description=\"Dietary restrictions, health considerations, or eating patterns (e.g., gluten-free, plant-based, high-protein, dairy-free)\")\n",
    "    flavor_preferences: List[str] = Field(description=\"Dominant taste profiles and flavor characteristics the user seeks (e.g., bold and spicy, mild and creamy, tangy and citrusy)\")\n",
    "    daypart_preferences: List[str] = Field(description=\"Preferred times of day for different meal types based on rating patterns (e.g., hearty breakfast, light lunch, elaborate dinner)\")\n",
    "    lifestyle_tags: List[str] = Field(description=\"Behavioral patterns and cooking style indicators inferred from recipe choices (e.g., quick meals, entertainer, health-conscious, experimental cook)\")\n",
    "    convenience_preference: str = Field(description=\"Preference for recipe complexity (e.g., quick and easy, gourmet elaborate)\")\n",
    "    diversity_openness: str = Field(description=\"Willingness to try new cuisines (e.g., adventurous, selective, traditionalist, not defined)\")\n",
    "\n",
    "    notes: str = Field(description=\"Brief summary explaining the users overall food personality and any notable patterns in their preferences\")\n",
    "    justification: str = Field(description=\"Detailed explanation of how the profile was determined based on the users interaction history and ratings. Describe why the liked cuisines, cuisine preference, dietary preference, food preferences, cuisine preferences, dietary preferences, flavor preferences, daypart preferences, and lifestyle tags were chosen. Is not allowed to use quotes or complex punctuation in this field. Keep it between 100 and 200 words not more.\")\n",
    "    user_story: str = Field(description=\"Predictive narrative about the user s culinary evolution and potential future preferences. Describes their food journey, emerging patterns, and likely directions for taste exploration. Written to help predict what they might enjoy next based on their current trajectory and evolving palate.\")\n",
    "    future_preferences: str = Field(description=\"Speculative insights into the types of recipes and cuisines the user may be inclined to explore in the future. Based on their current preferences, suggest new food categories, cooking styles, or dietary trends they might be open to trying next. This helps in anticipating their evolving culinary interests.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68e46f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a structured user profile that captures their culinary tastes, dietary preferences, flavor inclinations, among others. This user profile will be used then for a Recommendation System. Ensure the profile is concise, reasonable and accurately reflects the users food personality based on their interaction history. Please provide a structured profile of the user using the following format: [  liked_cuisines (List of cuisines the user enjoys most, ranked by preference based on their interaction history and ratings)  cuisine_preference (Primary cuisine type the user gravitates towards (e.g., Mediterranean, Asian Fusion, Traditional American))  dietary_preference (Main dietary restriction or lifestyle the user follows (e.g., Vegetarian, Low-carb, No restrictions))  food_preferences (Preferred food categories and meal types (e.g., comfort food, healthy salads, baked goods, grilled meats))  top_cuisine_choices (Specific regional or ethnic cuisines the user frequently rates highly (e.g., Thai, Southern BBQ, French pastry))  dietary_preferences (Dietary restrictions, health considerations, or eating patterns (e.g., gluten-free, plant-based, high-protein, dairy-free))  flavor_preferences (Dominant taste profiles and flavor characteristics the user seeks (e.g., bold and spicy, mild and creamy, tangy and citrusy))  daypart_preferences (Preferred times of day for different meal types based on rating patterns (e.g., hearty breakfast, light lunch, elaborate dinner))  lifestyle_tags (Behavioral patterns and cooking style indicators inferred from recipe choices (e.g., quick meals, entertainer, health-conscious, experimental cook))  convenience_preference (Preference for recipe complexity (e.g., quick and easy, gourmet elaborate))  diversity_openness (Willingness to try new cuisines (e.g., adventurous, selective, traditionalist, not defined))  notes (Brief summary explaining the users overall food personality and any notable patterns in their preferences)  justification (Detailed explanation of how the profile was determined based on the users interaction history and ratings. Describe why the liked cuisines, cuisine preference, dietary preference, food preferences, cuisine preferences, dietary preferences, flavor preferences, daypart preferences, and lifestyle tags were chosen. Is not allowed to use quotes or complex punctuation in this field. Keep it between 100 and 200 words not more.)  user_story (Predictive narrative about the user s culinary evolution and potential future preferences. Describes their food journey, emerging patterns, and likely directions for taste exploration. Written to help predict what they might enjoy next based on their current trajectory and evolving palate.)  future_preferences (Speculative insights into the types of recipes and cuisines the user may be inclined to explore in the future. Based on their current preferences, suggest new food categories, cooking styles, or dietary trends they might be open to trying next. This helps in anticipating their evolving culinary interests.)  ]. Each fill of the structured output doesnt need to take more than 200 words keep it in mind. IMPORTANT: Do not use quotation marks or complex punctuation in your response. Use simple words and avoid any quotes, apostrophes, or special characters. Use the following interaction history as reference:\n"
     ]
    }
   ],
   "source": [
    "user_profile_prompt = f\"\"\"Generate a structured user profile that captures their culinary tastes, dietary preferences, flavor inclinations, among others. This user profile will be used then for a Recommendation System. Ensure the profile is concise, reasonable and accurately reflects the users food personality based on their interaction history. Please provide a structured profile of the user using the following format: {schema_to_prompt_with_descriptions(UserProfile)}. Each fill of the structured output doesnt need to take more than 200 words keep it in mind. IMPORTANT: Do not use quotation marks or complex punctuation in your response. Use simple words and avoid any quotes, apostrophes, or special characters. Use the following interaction history as reference:\"\"\"\n",
    "\n",
    "print(user_profile_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b60f6005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WITH ai_responses AS (\n",
      "  SELECT \n",
      "    s.user_id, \n",
      "    s.n_history,\n",
      "    s.history_string,\n",
      "    AI.GENERATE(('Generate a structured user profile that captures their culinary tastes, dietary preferences, flavor inclinations, among others. This user profile will be used then for a Recommendation System. Ensure the profile is concise, reasonable and accurately reflects the users food personality based on their interaction history. Please provide a structured profile of the user using the following format: [  liked_cuisines (List of cuisines the user enjoys most, ranked by preference based on their interaction history and ratings)  cuisine_preference (Primary cuisine type the user gravitates towards (e.g., Mediterranean, Asian Fusion, Traditional American))  dietary_preference (Main dietary restriction or lifestyle the user follows (e.g., Vegetarian, Low-carb, No restrictions))  food_preferences (Preferred food categories and meal types (e.g., comfort food, healthy salads, baked goods, grilled meats))  top_cuisine_choices (Specific regional or ethnic cuisines the user frequently rates highly (e.g., Thai, Southern BBQ, French pastry))  dietary_preferences (Dietary restrictions, health considerations, or eating patterns (e.g., gluten-free, plant-based, high-protein, dairy-free))  flavor_preferences (Dominant taste profiles and flavor characteristics the user seeks (e.g., bold and spicy, mild and creamy, tangy and citrusy))  daypart_preferences (Preferred times of day for different meal types based on rating patterns (e.g., hearty breakfast, light lunch, elaborate dinner))  lifestyle_tags (Behavioral patterns and cooking style indicators inferred from recipe choices (e.g., quick meals, entertainer, health-conscious, experimental cook))  convenience_preference (Preference for recipe complexity (e.g., quick and easy, gourmet elaborate))  diversity_openness (Willingness to try new cuisines (e.g., adventurous, selective, traditionalist, not defined))  notes (Brief summary explaining the users overall food personality and any notable patterns in their preferences)  justification (Detailed explanation of how the profile was determined based on the users interaction history and ratings. Describe why the liked cuisines, cuisine preference, dietary preference, food preferences, cuisine preferences, dietary preferences, flavor preferences, daypart preferences, and lifestyle tags were chosen. Is not allowed to use quotes or complex punctuation in this field. Keep it between 100 and 200 words not more.)  user_story (Predictive narrative about the user s culinary evolution and potential future preferences. Describes their food journey, emerging patterns, and likely directions for taste exploration. Written to help predict what they might enjoy next based on their current trajectory and evolving palate.)  future_preferences (Speculative insights into the types of recipes and cuisines the user may be inclined to explore in the future. Based on their current preferences, suggest new food categories, cooking styles, or dietary trends they might be open to trying next. This helps in anticipating their evolving culinary interests.)  ]. Each fill of the structured output doesnt need to take more than 200 words keep it in mind. IMPORTANT: Do not use quotation marks or complex punctuation in your response. Use simple words and avoid any quotes, apostrophes, or special characters. Use the following interaction history as reference:', s.history_string),\n",
      "        connection_id => 'us.kaggle-connection',\n",
      "        endpoint => 'gemini-2.5-flash',\n",
      "        model_params => JSON '{\"generationConfig\":{\"temperature\": 1.0, \"maxOutputTokens\": 2048, \"thinking_config\": {\"thinking_budget\": 1024} } }',\n",
      "        output_schema => 'liked_cuisines ARRAY<STRING>, cuisine_preference STRING, dietary_preference STRING, food_preferences ARRAY<STRING>, top_cuisine_choices ARRAY<STRING>, dietary_preferences ARRAY<STRING>, flavor_preferences ARRAY<STRING>, daypart_preferences ARRAY<STRING>, lifestyle_tags ARRAY<STRING>, convenience_preference STRING, diversity_openness STRING, notes STRING, justification STRING, user_story STRING, future_preferences STRING'\n",
      "    ) AS ai_result\n",
      "  FROM (SELECT * FROM `deliverable.users_parsed`) s\n",
      ")\n",
      "SELECT \n",
      "  *,\n",
      "  ai_result.full_response AS user_profile,\n",
      "  JSON_EXTRACT_SCALAR(ai_result.full_response, '$.candidates[0].content.parts[0].text') AS user_profile_text\n",
      "FROM ai_responses\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_profile_generation_query = f\"\"\"\n",
    "WITH ai_responses AS (\n",
    "  SELECT \n",
    "    s.user_id, \n",
    "    s.n_history,\n",
    "    s.history_string,\n",
    "    AI.GENERATE(('{user_profile_prompt}', s.history_string),\n",
    "        connection_id => '{CONNECTION_ID}',\n",
    "        endpoint => 'gemini-2.5-flash',\n",
    "        model_params => JSON '{{\"generationConfig\":{{\"temperature\": 1.0, \"maxOutputTokens\": 2048, \"thinking_config\": {{\"thinking_budget\": 1024}} }} }}',\n",
    "        output_schema => 'liked_cuisines ARRAY<STRING>, cuisine_preference STRING, dietary_preference STRING, food_preferences ARRAY<STRING>, top_cuisine_choices ARRAY<STRING>, dietary_preferences ARRAY<STRING>, flavor_preferences ARRAY<STRING>, daypart_preferences ARRAY<STRING>, lifestyle_tags ARRAY<STRING>, convenience_preference STRING, diversity_openness STRING, notes STRING, justification STRING, user_story STRING, future_preferences STRING'\n",
    "    ) AS ai_result\n",
    "  FROM (SELECT * FROM `{USERS_PARSED}`) s\n",
    ")\n",
    "SELECT \n",
    "  *,\n",
    "  ai_result.full_response AS user_profile,\n",
    "  JSON_EXTRACT_SCALAR(ai_result.full_response, '$.candidates[0].content.parts[0].text') AS user_profile_text\n",
    "FROM ai_responses\n",
    "\"\"\"\n",
    "\n",
    "print(user_profile_generation_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10a8f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WITH ai_responses AS (\n",
      "  SELECT \n",
      "    s.user_id, \n",
      "    s.n_history,\n",
      "    s.history_string,\n",
      "    AI.GENERATE(('Generate a structured user profile that captures their culinary tastes, dietary preferences, flavor inclinations, among others. This user profile will be used then for a Recommendation System. Ensure the profile is concise, reasonable and accurately reflects the users food personality based on their interaction history. Please provide a structured profile of the user using the following format: [  liked_cuisines (List of cuisines the user enjoys most, ranked by preference based on their interaction history and ratings)  cuisine_preference (Primary cuisine type the user gravitates towards (e.g., Mediterranean, Asian Fusion, Traditional American))  dietary_preference (Main dietary restriction or lifestyle the user follows (e.g., Vegetarian, Low-carb, No restrictions))  food_preferences (Preferred food categories and meal types (e.g., comfort food, healthy salads, baked goods, grilled meats))  top_cuisine_choices (Specific regional or ethnic cuisines the user frequently rates highly (e.g., Thai, Southern BBQ, French pastry))  dietary_preferences (Dietary restrictions, health considerations, or eating patterns (e.g., gluten-free, plant-based, high-protein, dairy-free))  flavor_preferences (Dominant taste profiles and flavor characteristics the user seeks (e.g., bold and spicy, mild and creamy, tangy and citrusy))  daypart_preferences (Preferred times of day for different meal types based on rating patterns (e.g., hearty breakfast, light lunch, elaborate dinner))  lifestyle_tags (Behavioral patterns and cooking style indicators inferred from recipe choices (e.g., quick meals, entertainer, health-conscious, experimental cook))  convenience_preference (Preference for recipe complexity (e.g., quick and easy, gourmet elaborate))  diversity_openness (Willingness to try new cuisines (e.g., adventurous, selective, traditionalist, not defined))  notes (Brief summary explaining the users overall food personality and any notable patterns in their preferences)  justification (Detailed explanation of how the profile was determined based on the users interaction history and ratings. Describe why the liked cuisines, cuisine preference, dietary preference, food preferences, cuisine preferences, dietary preferences, flavor preferences, daypart preferences, and lifestyle tags were chosen. Is not allowed to use quotes or complex punctuation in this field. Keep it between 100 and 200 words not more.)  user_story (Predictive narrative about the user s culinary evolution and potential future preferences. Describes their food journey, emerging patterns, and likely directions for taste exploration. Written to help predict what they might enjoy next based on their current trajectory and evolving palate.)  future_preferences (Speculative insights into the types of recipes and cuisines the user may be inclined to explore in the future. Based on their current preferences, suggest new food categories, cooking styles, or dietary trends they might be open to trying next. This helps in anticipating their evolving culinary interests.)  ]. Each fill of the structured output doesnt need to take more than 200 words keep it in mind. IMPORTANT: Do not use quotation marks or complex punctuation in your response. Use simple words and avoid any quotes, apostrophes, or special characters. Use the following interaction history as reference:', s.history_string),\n",
      "        connection_id => 'us.kaggle-connection',\n",
      "        endpoint => 'gemini-2.5-flash',\n",
      "        model_params => JSON '{\"generationConfig\":{\"temperature\": 1.0, \"maxOutputTokens\": 2048, \"thinking_config\": {\"thinking_budget\": 1024} } }',\n",
      "        output_schema => 'liked_cuisines ARRAY<STRING>, cuisine_preference STRING, dietary_preference STRING, food_preferences ARRAY<STRING>, top_cuisine_choices ARRAY<STRING>, dietary_preferences ARRAY<STRING>, flavor_preferences ARRAY<STRING>, daypart_preferences ARRAY<STRING>, lifestyle_tags ARRAY<STRING>, convenience_preference STRING, diversity_openness STRING, notes STRING, justification STRING, user_story STRING, future_preferences STRING'\n",
      "    ) AS ai_result\n",
      "  FROM (SELECT * FROM `deliverable.users_parsed`) s\n",
      ")\n",
      "SELECT \n",
      "  *,\n",
      "  ai_result.full_response AS user_profile,\n",
      "  JSON_EXTRACT_SCALAR(ai_result.full_response, '$.candidates[0].content.parts[0].text') AS user_profile_text\n",
      "FROM ai_responses\n",
      "\n",
      "{\n",
      "  \"convenience_preference\": \"quick and easy\",\n",
      "  \"cuisine_preference\": \"comfort American\",\n",
      "  \"daypart_preferences\": [\n",
      "    \"dinner\",\n",
      "    \"lunch\"\n",
      "  ],\n",
      "  \"dietary_preference\": \"no restrictions\",\n",
      "  \"dietary_preferences\": [\n",
      "    \"meat eater\",\n",
      "    \"dairy friendly\"\n",
      "  ],\n",
      "  \"diversity_openness\": \"selective\",\n",
      "  \"flavor_preferences\": [\n",
      "    \"savory\",\n",
      "    \"cheesy\",\n",
      "    \"bold\",\n",
      "    \"spicy\",\n",
      "    \"garlicky\",\n",
      "    \"crispy\"\n",
      "  ],\n",
      "  \"food_preferences\": [\n",
      "    \"comfort food\",\n",
      "    \"hearty meals\",\n",
      "    \"family friendly\",\n",
      "    \"pasta dishes\",\n",
      "    \"fried foods\"\n",
      "  ],\n",
      "  \"future_preferences\": \"This user may enjoy exploring variations within their favorite comfort food genres such as different regional Mexican dishes or diverse Italian pasta preparations. They might also appreciate hearty stews casseroles or slow-cooker meals that offer rich flavors and are suitable for family dinners. Exploring more robust spice blends in their current favorite cuisines could also be appealing. Given their adaptability with ingredients they might be open to recipes that encourage creative substitutions while maintaining a familiar comfort food feel. They could also be introduced to global comfort foods that align with their savory cheesy or spicy preferences such as Indian curries or British pies.\",\n",
      "  \"justification\": \"Based on five-star ratings for Mexican burritos Italian sausage pasta American fried chicken and egg salad. The user consistently enjoys comfort food dishes that are hearty and family friendly. Their comments show a preference for robust flavors like extra garlic and spices. They are an adaptable cook willing to make small changes like using green pepper or different beer. Prep and cook times are generally short reflecting a convenience preference. The lower rating for pumpkin pasta indicates some selectivity and a preference for savory over potentially sweet savory combinations. Their overall food personality is family centric and flavor driven preferring familiar yet customizable dishes.\",\n",
      "  \"lifestyle_tags\": [\n",
      "    \"family focused\",\n",
      "    \"adaptable cook\",\n",
      "    \"comfort food seeker\",\n",
      "    \"quick meals\"\n",
      "  ],\n",
      "  \"liked_cuisines\": [\n",
      "    \"Mexican\",\n",
      "    \"American Southern\",\n",
      "    \"Italian\",\n",
      "    \"American Deli\"\n",
      "  ],\n",
      "  \"notes\": \"This user enjoys hearty, family-friendly comfort food with robust and savory flavors. They are an adaptable cook, making minor substitutions to recipes to suit their taste or available ingredients. They appreciate quick and easy preparation.\",\n",
      "  \"top_cuisine_choices\": [\n",
      "    \"Tex-Mex\",\n",
      "    \"Southern American\",\n",
      "    \"Italian-American\"\n",
      "  ],\n",
      "  \"user_story\": \"This user's culinary journey began with a strong foundation in comforting, family-friendly meals. Initially gravitating towards classic American and Tex-Mex dishes, they've shown a consistent preference for hearty, flavor-rich recipes that can be easily adapted. Their enjoyment of robust spices and savory profiles has grown, leading them to experiment with adding extra garlic or adjusting spice levels. They value efficiency in the kitchen, often choosing recipes with short preparation times, but are not afraid to make small changes to improve flavor or texture. In the future, this user will likely continue to explore variations of their beloved comfort foods, perhaps delving into more regional specific dishes within Mexican or Italian cuisines, or discovering new global comfort foods that resonate with their preference for bold, savory tastes and family appeal. Their palate is evolving towards a broader appreciation of well-seasoned and satisfying meals.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5601/2933704288.py:7: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  df_users_profiles.to_gbq(\n",
      "100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n"
     ]
    }
   ],
   "source": [
    "print(user_profile_generation_query)\n",
    "user_rows = client.query_and_wait(user_profile_generation_query)\n",
    "df_users_profiles = user_rows.to_dataframe()\n",
    "\n",
    "print(json.dumps(json.loads(df_users_profiles['user_profile_text'].iloc[0]), indent=2))\n",
    "\n",
    "df_users_profiles.to_gbq(\n",
    "    destination_table=f\"{PROJECT_ID}.{USERS_PROFILES_TABLE}\",\n",
    "    if_exists='replace',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1244d8",
   "metadata": {},
   "source": [
    "# Vector Search vs ALS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2585d06",
   "metadata": {},
   "source": [
    "We begin creating the text embeddings for both users and recipes, as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a34726e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x72ee74fcf640>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(f\"\"\"\n",
    "ALTER TABLE `{PROJECT_ID}.{USERS_PROFILES_TABLE}`\n",
    "ADD COLUMN text_embedding ARRAY<FLOAT64>\n",
    "\"\"\")\n",
    "\n",
    "client.query_and_wait(f\"\"\"\n",
    "UPDATE `{PROJECT_ID}.{USERS_PROFILES_TABLE}` AS t\n",
    "SET t.text_embedding = s.ml_generate_embedding_result\n",
    "FROM (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    ml_generate_embedding_result\n",
    "  FROM\n",
    "    ML.GENERATE_EMBEDDING(\n",
    "      MODEL `{SCHEMA_NAME}.text_embedding_model`,\n",
    "      (\n",
    "        SELECT\n",
    "          user_id,\n",
    "          user_profile_text AS content\n",
    "        FROM `{PROJECT_ID}.{USERS_PROFILES_TABLE}`\n",
    "      ),\n",
    "      STRUCT(TRUE AS flatten_json_output, {OUT_DIM} AS OUTPUT_DIMENSIONALITY, 'RETRIEVAL_QUERY' AS task_type)\n",
    "    )\n",
    ") AS s\n",
    "WHERE t.user_id = s.user_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query_and_wait(f\"\"\"\n",
    "ALTER TABLE `{PROJECT_ID}.{RECIPES_PROFILES_TABLE}`\n",
    "ADD COLUMN text_embedding ARRAY<FLOAT64>\n",
    "\"\"\")\n",
    "\n",
    "# Create Vector Embeddings for the recipe profiles\n",
    "client.query_and_wait(f\"\"\"\n",
    "UPDATE `{PROJECT_ID}.{RECIPES_PROFILES_TABLE}` AS t\n",
    "SET t.text_embedding = s.ml_generate_embedding_result\n",
    "FROM (\n",
    "  SELECT\n",
    "    recipe_id,\n",
    "    ml_generate_embedding_result\n",
    "  FROM\n",
    "    ML.GENERATE_EMBEDDING(\n",
    "      MODEL `{SCHEMA_NAME}.text_embedding_model`,\n",
    "      (\n",
    "        SELECT\n",
    "          recipe_id,\n",
    "          recipe_profile_text AS content\n",
    "        FROM `{PROJECT_ID}.{RECIPES_PROFILES_TABLE}`\n",
    "      ),\n",
    "      STRUCT(TRUE AS flatten_json_output, {OUT_DIM} AS OUTPUT_DIMENSIONALITY, 'RETRIEVAL_DOCUMENT' AS task_type)\n",
    "    )\n",
    ") AS s\n",
    "WHERE t.recipe_id = s.recipe_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse column to exclude recipe_history from vector search\n",
    "df = client.query_and_wait(f\"\"\"\n",
    "SELECT * FROM `{PROJECT_ID}.{USERS_PARSED}`\n",
    "\"\"\").to_dataframe()\n",
    "\n",
    "df['recipes_to_exclude'] = df['user_history'].apply(lambda x: [entry['recipe_id'] for entry in x])\n",
    "\n",
    "# Update entire table with the new column\n",
    "df.to_gbq(\n",
    "    destination_table=f\"{PROJECT_ID}.{USERS_PARSED}\",\n",
    "    if_exists='replace',\n",
    ")\n",
    "\n",
    "# Add new column to user profiles table via left join\n",
    "client.query_and_wait(f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{USERS_PROFILES_TABLE}` AS\n",
    "SELECT u.*, p.recipes_to_exclude, p.rec_gt\n",
    "FROM `{PROJECT_ID}.{USERS_PROFILES_TABLE}` u\n",
    "LEFT JOIN `{PROJECT_ID}.{USERS_PARSED}` p USING(user_id)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999d2c9",
   "metadata": {},
   "source": [
    "We could then reduce the search space of the vector search query using business logic. For example, we could filter recipes by cuisine, meal type, or dietary restrictions based on the user's preferences. This would help in retrieving more relevant recommendations. But, it is out of the scope of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15918040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f38dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "754a6549",
   "metadata": {},
   "source": [
    "## Naive Approach (Collaborative Filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973fc386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3adda804",
   "metadata": {},
   "source": [
    "## Simple Vector Search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f764e",
   "metadata": {},
   "source": [
    "This semantic search approach address in certain way the cold-start problem, as it can recommend new recipes that have not been rated yet, based on their content and similarity to the user's profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f88f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b22ec48",
   "metadata": {},
   "source": [
    "## HyDE (Hypothetical Document Embedding) Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6a220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "429c05b4",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc7ad7",
   "metadata": {},
   "source": [
    "Traditional Rec Sys methods fail to determine why a recommendation is relevant to a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3a2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a034900",
   "metadata": {},
   "source": [
    "We see in other competitions like [H&M](https://www.kaggle.com/code/julian3833/h-m-implicit-als-model-0-014) and in papers like ...\n",
    "\n",
    "If we'd had a more reliable retriever (powered by any algorithm, heuristic or methodology), we could have used `AI.GENERATE` method to re-rank the retrieved candidates as in [LlamaRec](https://arxiv.org/pdf/2311.02089). Some RecSys ideas can be found in more advanced papers like [LRU](https://arxiv.org/pdf/2310.02367) or [Generative Retrieval](https://papers.neurips.cc/paper_files/paper/2023/file/20dcab0f14046a5c6b02b61da9f13229-Paper-Conference.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0bd36",
   "metadata": {},
   "source": [
    "# LLM-as-a-Judge as middle ground between Offline Metrics and A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3c27f",
   "metadata": {},
   "source": [
    "Inspired by the work of [Spotify](https://arxiv.org/abs/2508.08777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b82f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2026f14",
   "metadata": {},
   "source": [
    "Following the ideas of this [Spotify paper](https://dl.acm.org/doi/pdf/10.1145/3705328.3759305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e1a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06532c41",
   "metadata": {},
   "source": [
    "# UI with Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711751a",
   "metadata": {},
   "source": [
    "# Summary and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65980f1c",
   "metadata": {},
   "source": [
    "## Feedback on BigQuery AI features\n",
    "- We found difficult at the beggining to pass the description of the attributes of the Pydantic models (used in libraries like LangChain and Instructor) as schema for the LLM calls. As you see in the code, we had to create a function to create a part of the prompt with the description of each attribute. It would be great to have a more straightforward way to do this.\n",
    "- The LLM calls are quite slow, even using the lightweight models. We had to limit the number of recipes and users to process. It would be great to have a way to speed up the calls, and show the progress of the calls.\n",
    "- If a response is too lengthy and surpasses the maximum tokens limit, it may cause errors related to quotation marks. Improving error messages and handling for these cases would make debugging easier and prevent the entire query from failing due to such edge cases.\n",
    "- We found that sometimes the Gemini Embedding 001 model returns empty embeddings for certain inputs. ...\n",
    "- Use two decimal places for the temperature value lead into an error in the SQL query.\n",
    "\n",
    "## User Survey on BigQuery AI features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5988be1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
