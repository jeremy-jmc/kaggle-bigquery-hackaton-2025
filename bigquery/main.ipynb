{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09f5ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-gbq in c:\\users\\renato\\anaconda3\\lib\\site-packages (0.29.2)\n",
      "Requirement already satisfied: google-cloud-bigquery in c:\\users\\renato\\anaconda3\\lib\\site-packages (3.36.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\renato\\anaconda3\\lib\\site-packages (14.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (69.5.1)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (2.2.2)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (1.9.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.10.2 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (2.25.1)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (1.2.2)\n",
      "Requirement already satisfied: packaging>=22.0.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas-gbq) (24.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.32.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq) (6.31.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq) (1.26.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-auth>=2.13.0->pandas-gbq) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-auth>=2.13.0->pandas-gbq) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-auth>=2.13.0->pandas-gbq) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq) (2.0.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->pandas-gbq) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->pandas-gbq) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas-gbq) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas-gbq google-cloud-bigquery pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f583cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "from pandas_gbq import to_gbq\n",
    "from slugify import slugify\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5c72621",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/food_recsys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79e35d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipe = pl.read_csv(os.path.join(DATA_PATH, \"raw\",\"raw-data_recipe.csv\"))\n",
    "df_interaction = pl.read_csv(os.path.join(DATA_PATH, \"raw\", \"raw-data_interaction.csv\"))\n",
    "df_test_rating = pl.read_csv(os.path.join(DATA_PATH, \"raw\",\"core-data-test_rating.csv\"))\n",
    "df_train_rating = pl.read_csv(os.path.join(DATA_PATH, \"raw\",\"core-data-train_rating.csv\"))\n",
    "df_valid_rating = pl.read_csv(os.path.join(DATA_PATH, \"raw\",\"core-data-valid_rating.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "219d16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_colnames(cols):\n",
    "    norm = []\n",
    "    for c in cols:\n",
    "        c2 = re.sub(r\"[^0-9a-zA-Z]+\", \"_\", c).strip(\"_\").lower()\n",
    "        norm.append(c2)\n",
    "    return norm\n",
    "\n",
    "def pick_first(df: pl.DataFrame, candidates, default=None):\n",
    "    cols = set(df.columns)\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return default\n",
    "\n",
    "def normalize_df(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.rename({old: new for old,new in zip(df.columns, normalize_colnames(df.columns))})\n",
    "\n",
    "df_recipe       = normalize_df(df_recipe)\n",
    "df_interaction  = normalize_df(df_interaction)\n",
    "df_train_rating = normalize_df(df_train_rating)\n",
    "df_valid_rating = normalize_df(df_valid_rating)\n",
    "df_test_rating  = normalize_df(df_test_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43ef1d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recipe_id', 'recipe_name', 'aver_rate', 'image_url', 'review_nums', 'ingredients', 'cooking_directions', 'nutritions', 'reviews']\n",
      "['user_id', 'recipe_id', 'rating', 'datelastmodified']\n",
      "['user_id', 'recipe_id', 'rating', 'datelastmodified']\n",
      "['user_id', 'recipe_id', 'rating', 'datelastmodified']\n",
      "['user_id', 'recipe_id', 'rating', 'datelastmodified']\n"
     ]
    }
   ],
   "source": [
    "print(df_recipe.columns)\n",
    "print(df_interaction.columns)\n",
    "print(df_train_rating.columns)\n",
    "print(df_valid_rating.columns)\n",
    "print(df_test_rating.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "462c319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_interaction(core: pl.DataFrame) -> pl.DataFrame:\n",
    "    date_col = pick_first(core, [\"datelastmodified\", \"dateLastModified\", \"date_last_modified\", \"timestamp\"], None)\n",
    "\n",
    "    cast_exprs = []\n",
    "    if \"user_id\" in core.columns:\n",
    "        cast_exprs.append(pl.col(\"user_id\").cast(pl.Utf8))\n",
    "    if \"recipe_id\" in core.columns:\n",
    "        cast_exprs.append(pl.col(\"recipe_id\").cast(pl.Utf8))\n",
    "    if \"rating\" in core.columns:\n",
    "        cast_exprs.append(pl.col(\"rating\").cast(pl.Float64))\n",
    "    if date_col:\n",
    "        cast_exprs.append(\n",
    "            pl.col(date_col)\n",
    "              .cast(pl.Utf8)\n",
    "              .str.replace(\"\\n\", \"\")\n",
    "              .str.to_datetime(strict=False)\n",
    "              .alias(date_col)\n",
    "        )\n",
    "\n",
    "    core = core.with_columns(cast_exprs)\n",
    "\n",
    "    if date_col and date_col in core.columns:\n",
    "        core = core.with_columns([\n",
    "            pl.col(date_col).dt.month().alias(\"month\"),\n",
    "            pl.col(date_col).dt.quarter().alias(\"quarter\"),\n",
    "        ])\n",
    "\n",
    "    core = core.drop_nulls()\n",
    "\n",
    "    if date_col and date_col in core.columns:\n",
    "        core = core.sort(date_col)\n",
    "\n",
    "    core = core.unique()\n",
    "\n",
    "    return core\n",
    "\n",
    "df_recipe = df_recipe.with_columns([\n",
    "    pl.col(\"recipe_id\").cast(pl.Utf8),\n",
    "    pl.col(\"recipe_name\").cast(pl.Utf8),\n",
    "    pl.col(\"aver_rate\").cast(pl.Float64),\n",
    "    pl.col(\"image_url\").cast(pl.Utf8),\n",
    "    pl.col(\"review_nums\").cast(pl.Int64),\n",
    "    pl.col(\"ingredients\").cast(pl.Utf8),\n",
    "    pl.col(\"cooking_directions\").cast(pl.Utf8),\n",
    "    pl.col(\"nutritions\").cast(pl.Utf8),\n",
    "    pl.col(\"reviews\").cast(pl.Utf8),\n",
    "])\n",
    "\n",
    "df_interaction = clean_df_interaction(df_interaction)\n",
    "df_train_rating = clean_df_interaction(df_train_rating)\n",
    "df_valid_rating = clean_df_interaction(df_valid_rating)\n",
    "df_test_rating  = clean_df_interaction(df_test_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c17334",
   "metadata": {},
   "source": [
    "Consolidating features of recipes in 1 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02a319d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid  = pick_first(df_recipe, [\"recipe_id\",\"id\",\"rid\"], None)\n",
    "ttl  = pick_first(df_recipe, [\"title\",\"recipe_name\", \"name\"], None)\n",
    "tags = pick_first(df_recipe, [\"tags\",\"tag_list\"], None)\n",
    "ing  = pick_first(df_recipe, [\"ingredients\",\"ingredient\",\"ingr\",\"ing\"], None)\n",
    "img  = pick_first(df_recipe, [\"image_url\",\"img_url\",\"image\",\"picture\"], None)\n",
    "desc = pick_first(df_recipe, [\"description\",\"summary\",\"text\"], None)\n",
    "cook = pick_first(df_recipe, [\"cooking_directions\",\"directions\",\"steps\"], None)\n",
    "nut  = pick_first(df_recipe, [\"nutritions\",\"nutrition\",\"nutrients\"], None)\n",
    "rev  = pick_first(df_recipe, [\"reviews\",\"review\",\"comments\"], None)\n",
    "# aver_rate, review_nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa48632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rid is None:\n",
    "    raise ValueError(\"No encontré columna de ID de receta en df_recipe (candidatos: recipe_id/id/rid).\")\n",
    "\n",
    "def safe_str(col): \n",
    "    return pl.when(pl.col(col).is_not_null()).then(pl.col(col).cast(pl.Utf8)).otherwise(pl.lit(\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "beb69ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recipe_cols = [c for c in [rid, ttl, tags, ing, desc, img, cook, nut, rev] if c]\n",
    "recipes_canon = pl.DataFrame({c: df_recipe[c] for c in recipe_cols})\n",
    "\n",
    "combined_parts = []\n",
    "if ttl:  combined_parts.append(pl.lit(\"Title: \")       + safe_str(ttl))\n",
    "if tags: combined_parts.append(pl.lit(\" | Tags: \")     + safe_str(tags))\n",
    "if ing:  combined_parts.append(pl.lit(\" | Ingredients: \")+ safe_str(ing))\n",
    "if desc: combined_parts.append(pl.lit(\" | Desc: \")     + safe_str(desc))\n",
    "if cook: combined_parts.append(pl.lit(\" | Cooking: \")  + safe_str(cook))\n",
    "if nut:  combined_parts.append(pl.lit(\" | Nutrition: \")+ safe_str(nut))\n",
    "if rev:  combined_parts.append(pl.lit(\" | Reviews: \")  + safe_str(rev))\n",
    "\n",
    "combined_text = combined_parts[0]\n",
    "for p in combined_parts[1:]:\n",
    "    combined_text = combined_text + p\n",
    "\n",
    "recipes_canon = recipes_canon.with_columns([\n",
    "    combined_text.alias(\"combined_text\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d1eb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_canon = recipes_canon.rename({rid: \"recipe_id\"})\n",
    "if ttl:  recipes_canon = recipes_canon.rename({ttl: \"title\"})\n",
    "if tags: recipes_canon = recipes_canon.rename({tags: \"tags\"})\n",
    "if ing:  recipes_canon = recipes_canon.rename({ing: \"ingredients\"})\n",
    "if desc: recipes_canon = recipes_canon.rename({desc: \"description\"})\n",
    "if img:  recipes_canon = recipes_canon.rename({img: \"image_url\"})\n",
    "if cook: recipes_canon = recipes_canon.rename({cook: \"cooking_directions\"})\n",
    "if nut:  recipes_canon = recipes_canon.rename({nut: \"nutritions\"})\n",
    "if rev:  recipes_canon = recipes_canon.rename({rev: \"reviews\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdd5296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canon_interactions(df: pl.DataFrame, split_name: str) -> pl.DataFrame:\n",
    "    df = df.clone()\n",
    "    df = normalize_df(df)\n",
    "    uid = pick_first(df, [\"user_id\",\"uid\",\"user\"], None)\n",
    "    rid = pick_first(df, [\"recipe_id\",\"rid\",\"item_id\",\"iid\"], None)\n",
    "    rat = pick_first(df, [\"rating\",\"score\",\"stars\",\"y\"], None)\n",
    "    ts  = pick_first(df, [\"timestamp\",\"ts\",\"time\"], None)\n",
    "\n",
    "    # Columns month / quarter may already come from clean_df_interaction\n",
    "    has_month = \"month\" in df.columns\n",
    "    has_quarter = \"quarter\" in df.columns\n",
    "\n",
    "    cols = {}\n",
    "    if uid is None or rid is None:\n",
    "        raise ValueError(f\"Faltan columnas en interacciones ({split_name}): user_id y/o recipe_id.\")\n",
    "    cols[\"user_id\"] = df[uid]\n",
    "    cols[\"recipe_id\"] = df[rid]\n",
    "\n",
    "    if rat: cols[\"rating\"] = df[rat].cast(pl.Float64)\n",
    "    if ts:  cols[\"timestamp\"] = df[ts]\n",
    "    if has_month: cols[\"month\"] = df[\"month\"].cast(pl.Int64)\n",
    "    if has_quarter: cols[\"quarter\"] = df[\"quarter\"].cast(pl.Int64)\n",
    "\n",
    "    out = pl.DataFrame(cols).with_columns([pl.lit(split_name).alias(\"split\")])\n",
    "    return out\n",
    "\n",
    "df_inter_train = canon_interactions(df_train_rating, \"train\")\n",
    "df_inter_valid = canon_interactions(df_valid_rating, \"valid\")\n",
    "df_inter_test  = canon_interactions(df_test_rating, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647be7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños:\n",
      "recipes: 49698\n",
      "interactions: 3794003\n",
      "interactions columns: ['user_id', 'recipe_id', 'rating', 'month', 'quarter', 'split']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nTamaños:\\nrecipes: 49698\\ninteractions: 4887848\\ninteractions columns: ['user_id', 'recipe_id', 'rating', 'month', 'quarter', 'split']\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df_inter_full = canon_interactions(df_interaction, \"raw\")\n",
    "    interactions_canon = pl.concat([df_inter_train, df_inter_valid, df_inter_test, df_inter_full], how=\"diagonal_relaxed\")\n",
    "except Exception:\n",
    "    interactions_canon = pl.concat([df_inter_train, df_inter_valid, df_inter_test], how=\"diagonal_relaxed\")\n",
    "\n",
    "\n",
    "# Cast core id columns\n",
    "interactions_canon = interactions_canon.with_columns([\n",
    "    pl.col(\"user_id\").cast(pl.Utf8),\n",
    "    pl.col(\"recipe_id\").cast(pl.Utf8)\n",
    "])\n",
    "\n",
    "subset_keys = [c for c in [\"user_id\",\"recipe_id\"] if c in interactions_canon.columns]\n",
    "interactions_canon = interactions_canon.unique(subset=subset_keys, keep=\"first\")\n",
    "\n",
    "recipes_canon = recipes_canon.with_columns([\n",
    "    pl.col(\"recipe_id\").cast(pl.Utf8)\n",
    "]).unique(subset=[\"recipe_id\"], keep=\"first\")\n",
    "\n",
    "print(\"Tamaños:\")\n",
    "print(\"recipes:\", recipes_canon.height)\n",
    "print(\"interactions:\", interactions_canon.height)\n",
    "print(\"interactions columns:\", interactions_canon.columns)\n",
    "\n",
    "\"\"\"\n",
    "Tamaños:\n",
    "recipes: 49698\n",
    "interactions: 4887848\n",
    "interactions columns: ['user_id', 'recipe_id', 'rating', 'month', 'quarter', 'split']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ab1a0",
   "metadata": {},
   "source": [
    "Subida Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19beefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"kaggle-bigquery-471522\"\n",
    "BQ_DATASET = \"foodrecsys\"        # cambia si quieres\n",
    "IF_EXISTS  = \"replace\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=262006177488-3425ks60hkk80fssi9vpohv88g6q1iqd.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fbigquery&state=pWeiqrfW549KRkTpCSTdBMlX1hvmEg&prompt=consent&access_type=offline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Subido a BigQuery: foodrecsys.recipes (con combined_text) y foodrecsys.interactions (con split)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p_rec = recipes_canon.to_pandas()\n",
    "p_int = interactions_canon.to_pandas()\n",
    "\n",
    "# Tipos para BQ\n",
    "p_rec = p_rec.astype({\n",
    "    \"recipe_id\": \"string\",\n",
    "    \"title\": \"string\",\n",
    "    #\"tags\": \"string\",\n",
    "    \"ingredients\": \"string\",\n",
    "    #\"description\": \"string\",\n",
    "    \"combined_text\": \"string\",\n",
    "    \"image_url\": \"string\",\n",
    "    \"cooking_directions\": \"string\",\n",
    "    \"nutritions\": \"string\",\n",
    "    \"reviews\": \"string\"\n",
    "}, errors=\"ignore\")\n",
    "\n",
    "# timestamp a datetime si existe\n",
    "if \"timestamp\" in p_int.columns:\n",
    "    p_int[\"timestamp\"] = pd.to_datetime(p_int[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "cast_int = {\n",
    "    \"user_id\": \"string\",\n",
    "    \"recipe_id\": \"string\",\n",
    "    \"rating\": \"float64\",\n",
    "    \"split\": \"string\"\n",
    "}\n",
    "if \"month\" in p_int.columns:\n",
    "    cast_int[\"month\"] = \"Int64\"  # nullable int\n",
    "if \"quarter\" in p_int.columns:\n",
    "    cast_int[\"quarter\"] = \"Int64\"\n",
    "\n",
    "p_int = p_int.astype(cast_int, errors=\"ignore\")\n",
    "\n",
    "# Subida\n",
    "to_gbq(p_rec, f\"{BQ_DATASET}.recipes\", project_id=PROJECT_ID, if_exists=IF_EXISTS)\n",
    "to_gbq(p_int, f\"{BQ_DATASET}.interactions\", project_id=PROJECT_ID, if_exists=IF_EXISTS)\n",
    "\n",
    "print(\"✓ Subido a BigQuery: \"\n",
    "      f\"{BQ_DATASET}.recipes (con combined_text) y {BQ_DATASET}.interactions (con split + month/quarter si existen)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fffa05",
   "metadata": {},
   "source": [
    "jeremy filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d70e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f4aca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using last 48 weeks of training data to predict next 2 weeks of ratings\n",
      "Final datasets: 1161 train interactions, 229 val interactions\n",
      "Users: 199, Recipes: 250\n",
      "Min interactions per user (train): 1\n",
      "Min interactions per user (val):   1\n",
      "            rating  rating_date\n",
      "count  1161.000000  1161.000000\n",
      "mean      4.537468     4.630851\n",
      "std       0.762607     0.765950\n",
      "min       1.000000     1.005784\n",
      "25%       4.000000     4.129266\n",
      "50%       5.000000     5.034451\n",
      "75%       5.000000     5.119908\n",
      "max       5.000000     5.200000\n",
      "           rating  rating_date\n",
      "count  229.000000   229.000000\n",
      "mean     4.650655     4.752999\n",
      "std      0.701041     0.699552\n",
      "min      1.000000     1.061886\n",
      "25%      4.000000     4.184215\n",
      "50%      5.000000     5.063263\n",
      "75%      5.000000     5.136036\n",
      "max      5.000000     5.200000\n",
      "Subiendo tablas filtradas a BigQuery...\n",
      "Final datasets: 1161 train interactions, 229 val interactions\n",
      "Users: 199, Recipes: 250\n",
      "Min interactions per user (train): 1\n",
      "Min interactions per user (val):   1\n",
      "            rating  rating_date\n",
      "count  1161.000000  1161.000000\n",
      "mean      4.537468     4.630851\n",
      "std       0.762607     0.765950\n",
      "min       1.000000     1.005784\n",
      "25%       4.000000     4.129266\n",
      "50%       5.000000     5.034451\n",
      "75%       5.000000     5.119908\n",
      "max       5.000000     5.200000\n",
      "           rating  rating_date\n",
      "count  229.000000   229.000000\n",
      "mean     4.650655     4.752999\n",
      "std      0.701041     0.699552\n",
      "min      1.000000     1.061886\n",
      "25%      4.000000     4.184215\n",
      "50%      5.000000     5.063263\n",
      "75%      5.000000     5.136036\n",
      "max      5.000000     5.200000\n",
      "Subiendo tablas filtradas a BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tablas subidas:\n",
      " - foodrecsys.train_interactions_windowed\n",
      " - foodrecsys.valid_interactions_windowed\n",
      " - foodrecsys.final_users\n",
      " - foodrecsys.final_recipes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Train / Validation windowing + enriched rating (rating_date) and upload\n",
    "# -----------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assumptions:\n",
    "# - df_train_rating / df_valid_rating came from the same raw distribution as in main.py\n",
    "# - Date column after normalization is 'datelastmodified'\n",
    "# - We keep only users & recipes meeting min interactions criteria across splits\n",
    "# - We create 4 BQ tables: train_interactions_windowed, valid_interactions_windowed,\n",
    "#   final_users, final_recipes.\n",
    "# If you need different names, adjust TABLE_* variables below.\n",
    "\n",
    "DATE_COL = \"datelastmodified\"\n",
    "PREV_WEEKS = 48\n",
    "POST_WEEKS = 2\n",
    "MIN_INTERACTIONS = 5\n",
    "MIN_INTERACTIONS_VAL = 3\n",
    "\n",
    "print(f\"Using last {PREV_WEEKS} weeks of training data to predict next {POST_WEEKS} weeks of ratings\")\n",
    "\n",
    "# Convert Polars => Pandas (lightweight here)\n",
    "core_train_rating = df_train_rating.to_pandas()\n",
    "core_val_rating   = df_valid_rating.to_pandas()\n",
    "\n",
    "# Ensure dtypes\n",
    "for c in [\"user_id\",\"recipe_id\"]:\n",
    "    if c in core_train_rating.columns:\n",
    "        core_train_rating[c] = core_train_rating[c].astype(str)\n",
    "        core_val_rating[c] = core_val_rating[c].astype(str)\n",
    "\n",
    "# Date parsing (should already be datetime, but enforce)\n",
    "for df_ in [core_train_rating, core_val_rating]:\n",
    "    if DATE_COL in df_.columns and not np.issubdtype(df_[DATE_COL].dtype, np.datetime64):\n",
    "        df_[DATE_COL] = pd.to_datetime(df_[DATE_COL], errors='coerce')\n",
    "\n",
    "# Drop rows with missing date or rating\n",
    "core_train_rating = core_train_rating.dropna(subset=[DATE_COL, \"rating\"])\\\n",
    "    .sort_values(DATE_COL)\n",
    "core_val_rating = core_val_rating.dropna(subset=[DATE_COL, \"rating\"])\\\n",
    "    .sort_values(DATE_COL)\n",
    "\n",
    "# Window training period (last PREV_WEEKS relative to its max date)\n",
    "max_train_date = core_train_rating[DATE_COL].max()\n",
    "min_date_val = max_train_date - pd.Timedelta(weeks=PREV_WEEKS)\n",
    "core_train_rating = core_train_rating.loc[lambda df: df[DATE_COL] >= min_date_val]\n",
    "\n",
    "# Limit validation horizon (first POST_WEEKS from its min date)\n",
    "min_val_date = core_val_rating[DATE_COL].min()\n",
    "max_date_val = min_val_date + pd.Timedelta(weeks=POST_WEEKS)\n",
    "core_val_rating = core_val_rating.loc[lambda df: df[DATE_COL] <= max_date_val]\n",
    "\n",
    "# Common users & recipes\n",
    "common_users = set(core_train_rating['user_id']).intersection(core_val_rating['user_id'])\n",
    "common_recipes = set(core_train_rating['recipe_id']).intersection(core_val_rating['recipe_id'])\n",
    "\n",
    "train_users = core_train_rating[\n",
    "    core_train_rating['user_id'].isin(common_users) &\n",
    "    core_train_rating['recipe_id'].isin(common_recipes)\n",
    "]\n",
    "val_users = core_val_rating[\n",
    "    core_val_rating['user_id'].isin(common_users) &\n",
    "    core_val_rating['recipe_id'].isin(common_recipes)\n",
    "]\n",
    "\n",
    "# Interaction counts post-initial filter\n",
    "train_user_counts = train_users['user_id'].value_counts()\n",
    "val_user_counts   = val_users['user_id'].value_counts()\n",
    "train_recipe_counts = train_users['recipe_id'].value_counts()\n",
    "val_recipe_counts   = val_users['recipe_id'].value_counts()\n",
    "\n",
    "users_min_it_train = set(train_user_counts[train_user_counts >= MIN_INTERACTIONS].index)\n",
    "users_min_it_val   = set(val_user_counts[val_user_counts >= MIN_INTERACTIONS_VAL].index)\n",
    "recipes_min_it_train = set(train_recipe_counts[train_recipe_counts >= MIN_INTERACTIONS].index)\n",
    "recipes_min_it_val   = set(val_recipe_counts[val_recipe_counts >= MIN_INTERACTIONS_VAL].index)\n",
    "\n",
    "final_users   = users_min_it_train.intersection(users_min_it_val)\n",
    "final_recipes = recipes_min_it_train.intersection(recipes_min_it_val)\n",
    "\n",
    "train_users = train_users[\n",
    "    train_users['user_id'].isin(final_users) &\n",
    "    train_users['recipe_id'].isin(final_recipes)\n",
    "]\n",
    "val_users = val_users[\n",
    "    val_users['user_id'].isin(final_users) &\n",
    "    val_users['recipe_id'].isin(final_recipes)\n",
    "]\n",
    "\n",
    "# ---- Antiquity bonus (modify_rating analogue) ----\n",
    "def modify_rating(df: pd.DataFrame, date_col: str = DATE_COL, alpha: float = 0.2) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        df['rating_date'] = df.get('rating', pd.Series([], dtype=float))\n",
    "        return df\n",
    "    min_d = df[date_col].min()\n",
    "    max_d = df[date_col].max()\n",
    "    denom = (max_d - min_d).total_seconds() or 1\n",
    "    age_norm = 1.0 - (df[date_col] - min_d).dt.total_seconds() / denom  # oldest => 1\n",
    "    df = df.copy()\n",
    "    df['rating'] = df['rating'].astype(float)\n",
    "    df['rating_date'] = df['rating'] + alpha * age_norm\n",
    "    return df\n",
    "\n",
    "train_users = modify_rating(train_users)\n",
    "val_users   = modify_rating(val_users)\n",
    "\n",
    "print(f\"Final datasets: {len(train_users)} train interactions, {len(val_users)} val interactions\")\n",
    "print(f\"Users: {len(final_users)}, Recipes: {len(final_recipes)}\")\n",
    "print(f\"Min interactions per user (train): {train_users['user_id'].value_counts().min()}\")\n",
    "print(f\"Min interactions per user (val):   {val_users['user_id'].value_counts().min()}\")\n",
    "\n",
    "# Basic sanity stats\n",
    "print(train_users[['rating','rating_date']].describe())\n",
    "print(val_users[['rating','rating_date']].describe())\n",
    "\n",
    "# Tables to upload\n",
    "TABLE_TRAIN = f\"{BQ_DATASET}.train_interactions_windowed\"\n",
    "TABLE_VALID = f\"{BQ_DATASET}.valid_interactions_windowed\"\n",
    "TABLE_USERS = f\"{BQ_DATASET}.final_users\"\n",
    "TABLE_RECIPES = f\"{BQ_DATASET}.final_recipes\"\n",
    "\n",
    "# Prepare small dimension tables\n",
    "final_users_df = pd.DataFrame({'user_id': sorted(final_users)})\n",
    "final_recipes_df = pd.DataFrame({'recipe_id': sorted(final_recipes)})\n",
    "\n",
    "# Cast for BQ\n",
    "for df_, name in [(train_users, 'train'), (val_users, 'val')]:\n",
    "    for c in ['user_id','recipe_id']:\n",
    "        df_[c] = df_[c].astype(str)\n",
    "    if DATE_COL in df_.columns:\n",
    "        df_[DATE_COL] = pd.to_datetime(df_[DATE_COL], errors='coerce')\n",
    "\n",
    "# Upload (idempotent replace by IF_EXISTS policy from earlier cell)\n",
    "print(\"Subiendo tablas filtradas a BigQuery...\")\n",
    "to_gbq(train_users, TABLE_TRAIN, project_id=PROJECT_ID, if_exists=IF_EXISTS)\n",
    "to_gbq(val_users,   TABLE_VALID, project_id=PROJECT_ID, if_exists=IF_EXISTS)\n",
    "to_gbq(final_users_df,   TABLE_USERS,   project_id=PROJECT_ID, if_exists=IF_EXISTS)\n",
    "to_gbq(final_recipes_df, TABLE_RECIPES, project_id=PROJECT_ID, if_exists=IF_EXISTS)\n",
    "print(\"✓ Tablas subidas:\")\n",
    "print(f\" - {TABLE_TRAIN}\")\n",
    "print(f\" - {TABLE_VALID}\")\n",
    "print(f\" - {TABLE_USERS}\")\n",
    "print(f\" - {TABLE_RECIPES}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
